<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-05-14T13:22:31-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">FOSS Academic</title><subtitle>A blog dedicated to two things. First, an exploration of Free and Open Source tools useful to academics. Second, an exploration of the culture, politics, and practices of FOSS.</subtitle><entry><title type="html">Decentralization or Noncentralization, Bluesky or the Fediverse?</title><link href="http://localhost:4000/2024/04/30/DecentralizedNoncentralized.html" rel="alternate" type="text/html" title="Decentralization or Noncentralization, Bluesky or the Fediverse?" /><published>2024-04-30T00:00:00-04:00</published><updated>2024-04-30T00:00:00-04:00</updated><id>http://localhost:4000/2024/04/30/DecentralizedNoncentralized</id><content type="html" xml:base="http://localhost:4000/2024/04/30/DecentralizedNoncentralized.html"><![CDATA[<p>I’m nearing wrapping up drafting <em>Move Slowly and Build Bridges</em>, <a href="/2024/02/11/Move-Slowy-Preview.html">my book about the fediverse</a>. I do several things in the book: provide some history, show the struggles of instance admins, talk about the politics of blocklists.</p>

<p>I also develop a concept in the book, “noncentralization.” In this blog post, I want to talk about what this means and contrast the term with the more popular one, “decentralization.” To do that, I want to contrast the fediverse with another system, Bluesky.</p>

<!-- more -->

<h2 id="decentralization-versus-noncentralization">Decentralization versus Noncentralization</h2>
<p>As I argue, the very term “decentralized” implies that there was once a center, something that has been broken up, <em>de</em>-centered. This process could work in reverse – something decentralized could be <em>re</em>-centralized at a later point. It might be hard to do, but it’s implied by the idea.</p>

<p>In contrast, <em>non</em>-centralized means just that: designed to avoid a center emerging. It’s a design goal from the outset. (Whether it is successful is another matter.)</p>

<p>I get this term from political philosophy, specifically federalism theory. As Glen Moots argues in <em><a href="https://www.routledge.com/The-Ashgate-Research-Companion-to-Federalism/Ward/p/book/9780367603021">The Ashgate Research Companion to Federalism</a></em>, in federalist political structures,</p>

<blockquote>
  <p>Power is diffused. Centralizing or concentrating power in a federalist system risks breaking the structure and spirit of the constitution. It negates the whole telos of federalism. Non-centralization applies to the United States, Canada, and Switzerland, for example. In each case, there is no central government that controls all the lines of political communication and decision-making. States, cantons, or provinces are not creatures of the federal government (Elazar 1984b 14).</p>
</blockquote>

<p>We might argue whether or not the US or Canada is truly non-centralized. But the point Moots is making is that the ideal political structure envisioned by federalism doesn’t involve breaking up an existing center. As Moots writes, “decentralization implies the existence of a central authority that can decentralize or recentralize as it pleases.” Noncentralization by contrast involves designing political structures so that there are many, smaller locations where power is exercised. This allows for a high degree of local autonomy coupled with a larger-scale agreement about shared ethical values. (In the case of the fediverse, I call such a structure “the covenantal fediverse,” but that’s a topic for another post.)</p>

<p>Now, in my work on alternative social media, I’m not talking about states. I’m talking about social media. But given that social media must be governed (e.g., moderated, have policies), and given that we’re now living in a time of federated social media, I think it’s a good idea to look to federalist political theory to think about how things might work.</p>

<p>The two main projects seeking to federate social media today are the ActivityPub-based fediverse and Bluesky. Drawing on the noncentalized/decentralized distinction, I would argue that Bluesky is decentralized – and as such will never truly be federated. The ActivityPub-based fediverse is closer to the noncentalized ideal. But it is vulnerable to centralization, too.</p>

<h2 id="bluesky-and-decentralization">Bluesky and decentralization</h2>
<p>Bluesky has the ambition to be a decentralized Twitter. To that end, Bluesky has started out centralized and is slowly spinning out parts of itself from the center to the edges.</p>

<p>A simple example is support for GIFs. Bluesky has <a href="https://bsky.app/profile/bsky.app/post/3kqy4mjw5eo2t">proudly declared they now let people post GIFs</a>… <em>powered by Tenor</em>. What’s Tenor? It’s a <a href="https://en.wikipedia.org/wiki/Tenor_(website)">Google-owned GIF repository and search engine</a> with <a href="https://tenor.com/gifapi/documentation">an API</a>. So people can “post” GIFs to Bluesky insofar as that means they pull in a GIF from another, centralized database of them and have it embedded in the stream.</p>

<p>In keeping with decentralization, Bluesky says that “custom GIFs” will be implemented later. I take that to mean they will allow uploading a .gif file from a local machine. You can’t do that now (I tried, and it just is a still image). So for now GIF posting is decentralized in that it involves two major services (Bluesky and Google’s Tenor), and in the future these centers might get broken up further.</p>

<p>It’s hard not to see this as symptomatic of Bluesky’s approach as a whole. It started out as one central service, Bsky.app, with the promise that people could run their own Personal Data Servers (PDSes) in the future (a future that is, to their credit, slowly happening).</p>

<p>But Bluesky distinguishes between “speech” and “reach,” meaning that while people can run their own PDSes and speak, their posts won’t appear across the network unless they are indexed or relayed – and Bluesky runs the only indexer. They promise that in the future that non-Bluesky employees can run indexers/relays, too, but that’s a costly proposition – much more so than running a PDS.</p>

<p>In the meantime, Bsky.app, the central Bluesky server, includes a connection to Twilio Segment, which is <a href="https://segment.com/">“The leading customer data platform, powered by CustomerAI”</a>.</p>

<figure>
  <img src="/assets/images/bskySegment.png" alt="A screenshot of my Noscript Firefox extension on bsky.app, showing Segment.com as a source for a script" />
  <figcaption>A screenshot of my Noscript Firefox extension on bsky.app, showing Segment.com as a source for a script</figcaption>
</figure>

<p>Segment’s presence on the site raises the specter of behavioral advertising – a possibility the company has never denied. Consider this Q and A between <a href="https://www.wired.com/story/bluesky-ceo-jay-graber-wont-enshittify-ads/">Bluesky CEO Jay Graber and <em>WIRED</em></a>:</p>

<blockquote>
  <p><strong>Are you thinking about advertisements at all?</strong></p>
</blockquote>

<blockquote>
  <p>There will always be free options, and we can’t enshittify the network with ads. This is where federation comes in. The fact that anyone can self-host and anyone can build on the software means that we’ll never be able to degrade the user experience in a way where people want to leave.</p>
</blockquote>

<p>That’s not a “no.” It’s hard to understand exactly what it is.</p>

<p>It might be, “we won’t do ads.” But then what’s the Segment integration for? Segment’s presence might just mean Bluesky will sell data to marketers but not allow ads. (After all, brands are certainly welcome on Bluesky and may want insights into their audiences.)</p>

<p>Or, it might be, “if we do ads <em>wrong</em> people will leave, so we better do them right.” That seems likely given the Segment integration.</p>

<p>Or maybe Graber’s answer means, “if we do allow ads, people can just move to another PDS and appview.” That is, we can run ads on our PDS/appview, but others may decide not to.</p>

<p>In any case, if the costs of running Bluesky infrastructure can be partially subsidized by ads or other behavioral marketing techniques (without “enshittifying” everything), then most likely there will be one central mechanism by which anyone wishing to subsidize their part of the network (e.g., a distinct PDS) can do so. If Bluesky runs this monetization system, then de facto third-party PDSes that use it will be closely tied to the center.</p>

<p>Decentralization also holds when we consider the underlying protocol Bluesky is making, ATProto, That’s being done by them alone. They promise it will be transferred to a standards body (e.g., the IETF) in the future so that it is more open. It could be that they do this, but it would replicate the pattern: they start with a center and then decentralize. The protocol will be made in-house, and even after being moved to something like the IETF, it can be dominated by Bluesky the company.</p>

<p>Overall, Bluesky is decentralized in the sense I’m using it here: there’s a center that’s being broken up. This might turn out for the best. <a href="https://steveklabnik.com/writing/how-does-bluesky-work">Steve Klabnik’s explainer</a> has a similar (if more sanguine) take:</p>

<blockquote>
  <p>…the BlueSky team has demonstrated, in my personal opinion, enough understanding and uncomfortableness with being in control here, and it’s designed in such a way that if other, better systems develop, you can move to them. They’ve also indicated that moving governance of did:plc to some sort of consensus model in the future is possible. There are options. Also, others could run a did:plc service and use that instead if they prefer, too.
I personally see this as an example of pragmatically shipping something, others see it as a nefarious plot. You’ll have to decide for yourself.</p>
</blockquote>

<p>So it’s a pragmatic choice to do everything centrally, ship it now, and devolve it to the edges over time.</p>

<p>But it seems to me that, no matter what, much will continue to flow to the center, either on purpose or through inertia. And edge-parts that misbehave (by Bluesky’s standards) might be recallable to the center. For example, if allowing just anyone to run an indexer causes problems down the road, Bluesky’s control could be re-asserted later.</p>

<h2 id="noncentralization-and-the-fediverse">Noncentralization and the fediverse</h2>
<p>I would argue that the ActivityPub-based fediverse is much closer to the noncentalized ideal I would prefer. By “fediverse” I mean the ActivityPub-based fediverse.</p>

<p>How?</p>

<p>Well, for one thing, there’s a whole host of different projects. From PeerTube to the Wordpress plugin, it’s a network of heterogenous social media services. ActivityPub allows for a range of technologies. Moreover, ActivityPub is already an open standard – it was that way from day 1. It supports a bewildering array of social media projects.</p>

<p>Now, you might argue “Mastodon is dominant.” Yes, Mastodon is dominant, but it’s not the only game in town. And even <em>if</em> the fediverse was mostly Mastodon, what does that mean? There are forks of Mastodon (Glitch, Hometown) and heavily modified Mastodon installations (awoo.space). Mastodon isn’t one thing – it’s many things.</p>

<p>You might say that there are points of centralization at the instance level: that an instance is a center. But they are not central to the network. There are tens of thousands of them, ranging from instances-of-one to large instances. And there’s no guarantee they will connect – they might have ethical disagreements. The smallest instance can block the biggest one. Indeed, that’s why instance blocking exists.</p>

<p>Now, you might say, “What about Threads?” And <em>that</em> is a concern of mine. The existing fediverse is so small that the appearance of a corporate-controlled network with 100 million+ accounts means that de facto there is now a center. That is indeed a problem.</p>

<p>There are solutions, though. One is #<a href="https://fedipact.online/">fedipact-like agreements</a> to block Meta. I endorse this. In my view, the whole point of federated, alternative social media is to be a better alternative to corporate social media, not a means to connect to it.</p>

<p>Another approach to Threads is to hope other big companies get involved in the fediverse to balance things out with Meta. With Meta here, let’s get Apple and Google and Microsoft to adopt ActivityPub. To cite Evan Prodromou, that’s a <a href="https://evanp.me/2023/12/26/big-fedi-small-fedi/">“Big Fedi” solution</a>.</p>

<p>I don’t like this solution, because I would rather see the fediverse be comprised of tens or even hundreds of thousands of small, self-governing communities. That would be closest to a noncentalized ideal: it remains a system where there was no center in the first place, where many small communities band together into a big network through mutual, shared ethical values, and any attempt to centralize will be resisted.</p>

<h2 id="bluesky-wont-be-federated">Bluesky won’t be federated</h2>
<p>Reading the documents and discourses, it’s clear to me Bluesky won’t be federated – it will be decentralized. It won’t be federated because it won’t be noncentralized. It is not being designed that way, and I do not believe it will ever be that way. Some of its centers are going to hold, which negates the idea of distributing power and control. And those things that are spun out to the edges could be recallable in particular ways.</p>

<p>The fediverse is closer to the ideal of noncentralization, but of course Threads indicates that such a thing is fragile. Designing a noncentralized system is hard work, and it can fail.</p>]]></content><author><name>RWG</name></author><category term="Bluesky" /><category term="Fediverse" /><category term="Goal 2" /><summary type="html"><![CDATA[I’m nearing wrapping up drafting Move Slowly and Build Bridges, my book about the fediverse. I do several things in the book: provide some history, show the struggles of instance admins, talk about the politics of blocklists. I also develop a concept in the book, “noncentralization.” In this blog post, I want to talk about what this means and contrast the term with the more popular one, “decentralization.” To do that, I want to contrast the fediverse with another system, Bluesky.]]></summary></entry><entry><title type="html">Reading the Online Harms Act with my Fediverse Admin Hat On</title><link href="http://localhost:4000/2024/04/10/Online-Harms-Act.html" rel="alternate" type="text/html" title="Reading the Online Harms Act with my Fediverse Admin Hat On" /><published>2024-04-10T00:00:00-04:00</published><updated>2024-04-10T00:00:00-04:00</updated><id>http://localhost:4000/2024/04/10/Online%20Harms%20Act</id><content type="html" xml:base="http://localhost:4000/2024/04/10/Online-Harms-Act.html"><![CDATA[<p>The <a href="https://www.canada.ca/en/canadian-heritage/services/online-harms.html">Online Harms Act</a> is currently the talk of Canada. As the government’s website describes it,</p>
<blockquote>
  <p>The internet is an exceptional tool for people of all ages to learn, play and connect with family, friends and those with similar interests. However, just like the outside world, the digital world can pose significant dangers. Social media can be used to sexually exploit children, promote self-harm to children, incite violence, put people’s safety at risk and foment hate. Online harms have real-world impacts with tragic, even fatal, consequences.</p>
</blockquote>

<blockquote>
  <p>The Government of Canada has introduced legislation to hold social media platforms accountable for addressing harmful content on their platforms and for creating a safer online space that protects all people in Canada, especially kids.</p>
</blockquote>

<p>As something that addresses speech on the internet – and includes some strong penalties for spreading hate speech – the Act has led to massive debates. I won’t summarize them here, but you can read thoughtful critiques from <a href="https://www.michaelgeist.ca/tag/online-harms-act/">Professor Michael Geist</a> and you can listen to a discussion on <a href="https://www.canadaland.com/podcast/85-the-hate-u-post/">Canadaland’s Backbench</a> to get a sense of things.</p>

<p>My interest here is not to delve into the controversies, but instead read the Act while wearing my Mastodon admin hat. I am one of the two admins of AoIR.social, a <a href="https://en.wikipedia.org/wiki/Mastodon_(social_network)">Mastodon</a> instance for members of the <a href="https://aoir.org/">Association of Internet Researchers</a>. AoIR.social gives our members access to <a href="https://en.wikipedia.org/wiki/Fediverse">the fediverse</a> – the global network of thousands of social media servers, with millions of users engaged in social media activities.</p>

<p>An initial question: does the Act apply to the tens of thousands of fediverse instances with their millions of users? Does it thus apply to AoIR.social? Considering that the Act defines “social media service” as “a website or application that is accessible in Canada, the primary purpose of which is to facilitate interprovincial or international online communication among users of the website or application by enabling them to access and share content” (page 5), then the answer is yes. AoIR.social operates internationally, including in Canada. So do many of the other tens of thousands of fediverse servers.</p>

<p>Since I’m one of the two admins of AoIR.social, am I affected? I believe so: I would be an “operator,” “a person that, through any means, operates a regulated service.” It could also be that the AoIR organization itself would be the operator, since in this Act “person” also applies to corporations.</p>

<p>The Act would create a Digital Safety Commission, an agency that would govern social media services. The Act notes this Commission should consider things like the size of the service and the operator’s financial and technical abilities. This is good – many fediverse instances are small and are run by individuals or a handful of folks. They also often run on very small budgets as not-for-profit organizations. Regardless, however, I believe small fediverse servers would be affected (unless they find a way to not be available to Canadians).</p>

<p>So: will the Act radically affect fediverse instances, such as AoIR.social? The Act specifically says our service should not harm freedom of expression, and reading it leads me to believe that AoIR.social won’t be affected in that manner. While we welcome debate and discussion, we’re not in the business of platforming the sorts of harmful content the Act discusses.</p>

<p>But, the implementation of the Act could prove to be very burdensome to the administration of fediverse instances, such as AoIR.social. Much is going to hinge on how the Act understands the fediverse.</p>

<!-- more -->

<h2 id="duties-of-operators-of-regulated-services">Duties of Operators of Regulated Services</h2>
<p>The Act is meant to regulate social media, and it lays out various duties social media service operators must follow.</p>

<p>The first is the duty to act responsibly: “The operator of a regulated service must implement measures that are adequate to mitigate the risk that users of the service will be exposed to harmful content on the service.”  Another is a duty to protect children, and related to both, there’s also the duty to make harmful content inaccessible to Canadians.</p>

<p>As a fediverse admin, I have two key questions about these duties. First, what is “harmful content”? This is defined on page 4 in the definitions section:</p>
<ul>
  <li>“(a) intimate content communicated without consent;</li>
  <li>(b) content that sexually victimizes a child or revictimizes a survivor;</li>
  <li>(c) content that induces a child to harm themselves;</li>
  <li>(d) content used to bully a child;</li>
  <li>(e) content that foments hatred;</li>
  <li>(f) content that incites violence; and</li>
  <li>(g) content that incites violent extremism or terrorism.”</li>
</ul>

<p>So, things like revenge “porn”, child sexual abuse material, hate speech, and terrorist speech are prohibited. There are definitions offered for each of these, so I won’t define them here. Frankly, I have no problem blocking these things.</p>

<p>The other question I have is about the responsibility to “mitigate the risk that users of the service will be exposed to harmful content….” It seems to me that this is not just about removing content that’s posted. It’s about reducing the likelihood AoIR.social members will see such harmful content.</p>

<p><em>This</em> is where I have a lot of concerns. Some things seem easy to do, but there are other things that I’m not sure about.</p>

<p>Put simply, the TL;DR summary of the issue is: does the Act consider something like a fediverse server an independent social media site? Or would the Act see the fediverse as a singular network, with traffic being load-balanced across multiple servers?</p>

<p>Let’s get into the details.</p>

<h2 id="whats-easily-done">What’s Easily Done</h2>
<p>The Act calls for social media to publish “Guidelines.” These “must be accessible and easy to use and must include (a) a standard of conduct that applies to users with respect to harmful content; and (b) a description of the measures that the operator implements with respect to harmful content on the service.”</p>

<p>This is pretty easy to comply with, because like many other Mastodon instances, <a href="https://aoir.social/about">AoIR.social has a code of conduct</a>. I believe our code is “accessible and easy to use,” and it explicitly establishes a standard of conduct, which includes prohibitions on the sorts of content the Act describes.</p>

<p>The Act also calls for social media to provide users with “tools to block users” – done and done, because this was baked into Mastodon from its early days.</p>

<p>And the duty to protect children is quite easy for AoIR.social since our membership is limited to dues-paying members of the Association of Internet Researchers, and I don’t think that population includes anyone under 20, let alone minors.</p>

<h2 id="whats-less-clear">What’s Less Clear</h2>
<h3 id="tools-and-processes-to-flag-harmful-content">Tools and processes to flag harmful content</h3>
<p>One feature called for is to “enable a user to easily flag to the operator content that is accessible on the service as being a particular type of harmful content.” That’s baked into Mastodon, so easy enough.</p>

<p>But some of it is not as easy to do, such as “notify a user who flagged content as being a particular type of harmful content of the operator’s receipt of the flag as well as of any measures taken by the operator with respect to the content or of the fact that no measures were taken.” Mastodon does not automatically do this, so it would have to be something the admin/mod does on their own. On AoIR.social, if a user flags something and we block it, we don’t really bother to go back to the original flagger and say we did so. We just do it and move on. I suppose we can do the extra step, but it will add work.</p>

<p>But some of it seems misguided to me: “notify a user who communicated content that was flagged as being a particular type of harmful content of the fact that the content was flagged as well as of any measures taken by the operator with respect to the content or of the fact that no measures were taken.” Mastodon <em>definitely</em> does not do this. I believe this is by design, because notifying people that they have had their content removed can invite more harassment. The approach on Mastodon is to block and not really let the blocked person know. I believe this is for safety purposes –- if we block someone’s content and tell them, they might harass us.</p>

<p>That’s not likely to happen if it’s an AoIR.social member. But the big issue is: <strong>does the Act require me to do these actions with people who are not on my server?</strong> If this is all meant to take place <em>within</em> my server, it’s probably not a problem. Most such in-server moderation is going to involve a discussion with the “user who communicated content that was flagged.” In the case of a user who posts something abhorrent, they’re going to be booted. In the case of someone who posts something borderline, we’re going to chat about it. It’s not going to be a formal process, but more personal.</p>

<p>However, if this is meant to govern my interactions with a user on a server <em>outside</em> my instance, I don’t think this is wise, and it could backfire. If, for example, some trolls are harassing people on AoIR.social, I might communicate with them to tell them to stop, but most likely I’m just going to block them (and hence remove their posts) and not explain myself. Explaining myself would probably lead to more harassment, both for the original victim and likely for me or other AoIR.social moderators.</p>

<p>How the Act handles this is going to matter. If the Act looks at the fediverse and sees a bunch of independent servers which can connect to one another and can sever those connections but have no power over each other, that’s fine. (This is how I think of the fediverse). I can moderate my own server easily enough, and even with the Act in force, the moderation burden might not change all that much (depending on how it is implemented – see below).</p>

<p>If, however, the Act sees a large social media network that distributes the load across multiple resources, then it’s going to raise a great deal of problems for admins like myself. It’s going to create big burdens – and could even lead to more harmful speech.</p>

<h3 id="digital-safety-plan">Digital Safety Plan</h3>
<p>The issue with how the Act would see the fediverse is really intense when it comes to the Digital Safety Plan section. “The operator of a regulated service must submit a digital safety plan to the [Digital Safety] Commission in respect of each regulated service that it operates,” the Act states.</p>

<p>The details are going to matter a great deal here. As someone attempting to immigrate to Canada, I have some familiarity with Canadian bureaucracy. Much of it is quite straightforward, but some of it is onerous and confusing. If AoIR.social will have to supply such a plan, what will it entail? How will it be submitted? Will it be like getting my social insurance number (which was super easy) or like going through the work permit process (which was pretty labor-intensive)?</p>

<p>Looking at the details, I have concerns. For example is point G of the Digital Safety Plan, which would ask me to report</p>
<blockquote>
  <p>information respecting (i) the number of times that content that was accessible on the service was flagged to the operator by users of the service as being harmful content, including the number of flags relating to each type of harmful content, (ii) the manner in which the operator triaged and assessed the flags, (iii) measures taken by the operator with respect to content that was flagged as being harmful content, and (iv) the time within which the operator took measures with respect to content that was flagged as being harmful content.</p>
</blockquote>

<p>This would be easy enough – again, <em>if it’s limited to my server.</em> AoIR.social members are a collegial, professional lot. I simply don’t expect any of them to post harmful content, and thus I don’t expect to have to often report that they flagged content on our own server. And maybe this would be the case. I can indeed interpret the Act’s “users of the service” to be limited to AoIR.social members.</p>

<p>But this does raise a separate potential problem. If the Act sees the fediverse as a bunch of independent servers, what happens when someone outside my server flags something on my server? For the sake of argument, let’s say AoIR.social is actually a bad actor on the fediverse, and our members share harmful content regularly, and that we don’t report each other (since we all agree with our harmful content-sharing project). Could we simply ignore the pleas of people outside our server to cut it out? Could our Digital Safety Plan simply say, “we didn’t get reports”? The Act has penalties for such things, but it would require someone outside our server to report us to the Commission who would then have to investigate. Meanwhile, we’re gleefully sharing harmful content (in this hypothetical example).</p>

<p>So, maybe the Act should require me (and other fedi instances) to document flags I get from outside my server – that is, maybe the Act <em>should</em> see the fediverse as one large network.</p>

<p>But if the Act requires me to document flags coming from outside my server, I could also imagine another problem: being burdened by reporting on malicious or coordinated flagging from outside one’s server. I would have to write up reports for those flags, even if they are done in bad faith. There is language about my being able to ignore “vexatious” or “frivolous” flags, but do I have document them, anyway, to prove that all the reports were, indeed, vexatious?</p>

<p>Taken as a whole, I think the Act should treat each instance as an independent entity.</p>

<h3 id="duty-to-make-certain-content-inaccessible">Duty to Make Certain Content Inaccessible</h3>
<p>Subsection 67 of the Act says that if an operator finds material that exploits children or revictimizes an adult, or finds nonconsensual materials (e.g., revenge “porn”), the operator has to block it and tell the person that it’s blocked. This has to be done in 24 hours.</p>

<p>Obviously, I 100% support this. AoIR.social would act with the swiftness if a member posts such material.</p>

<p>But again, the details are going to matter, and the way the Act understands the fediverse is going to be important. If I block content from another server – not my own – do I have to inform the creator of the content, who did so on the other server? Because that sort of thing often leads to harassment of moderators. I or one of the AoIR.social moderators might get targeted by the sort of person who would maliciously share such content.</p>

<p>The next point, subsection 68, discusses “trivial, frivolous, vexatious” or “bad faith” flags, stating operators can ignore those.</p>

<p>That’s good.</p>

<p>But: “If the operator dismisses the flag, it must, within the period that applies under subsection (5), notify the user who flagged the content of the dismissal.” Again, this is pretty problematic if it’s someone outside my server. The sort of person who submits trivial or vexatious reports is not the sort of person who is going to simply walk away when an admin or mod says to stop.</p>

<h3 id="the-appeals-process">The Appeals Process</h3>

<p>The question of whether I am responsible for reaching out to people on other servers or not is intensified by the “Representations” section (subsection 69), which describes a sort of appeals process:</p>

<blockquote>
  <p>“If the operator of a regulated service makes content inaccessible under subsection 67(1) or 68(3), the operator must, within the period provided for by regulations, give the user who communicated the content on the service and the user who flagged the content, if applicable, an opportunity to make representations as to whether the content is content that sexually victimizes a child or revictimizes a survivor or intimate content communicated without consent.”</p>
</blockquote>

<p>If I’m required to communicate with someone sharing CSAM on another server and ask them to justify their doing so (representing that it is actually OK to share), I will definitely be burdened. I simply want to block them. Or more likely block their server for engaging in poor moderation. I don’t want to negotiate the finer points of CSAM with people who share it.</p>

<p>This is compounded by the “Reconsideration Upon Request” (point 70): “At the request of the user who communicated the content on the service or the user who flagged the content, the operator of a regulated service must reconsider a decision that it made under subsection 69(2).” If I am asked to do this work with someone outside my server, then a full process could be:</p>

<ul>
  <li>consider it and judge it</li>
  <li>communicate with the CSAM provider (“Hey, is this really CSAM?”)</li>
  <li>Hear them out</li>
  <li>Decide</li>
  <li>Reconsider upon request</li>
  <li>Decide</li>
  <li>Reconsider again (“Reconsideration” is mentioned twice)</li>
</ul>

<p>This strikes me as pretty burdensome, as well as a vector for harassment.</p>

<p>And this is not just if the Act sees the fedi as one big network. It could lead to harassment if the Act sees fedi instances as independent, too.</p>

<p>Here’s how: the Act includes the appeals process, because if the Act requires a company like Meta to block stuff without any chance of appeal, that’s problematic, since Meta is going to use automated moderation and will make tons of mistakes.</p>

<p>But for small fediverse instances, I don’t really think a government-mandated appeals process is necessary, nor wanted. Most well-moderated fedi instances are just going to remove accounts of people who post harmful stuff. No appeals. No tolerance. They’re not courts of law. The approach many fedi admins take is: if you want to post X content, you’re free to do so on another server. Does the Act give a bad actor the right to appeal the decision of a fedi admin? I really, really hope not. It would be burdensome and actually cause more harm than good.</p>

<h3 id="duty-to-keep-records">Duty to Keep Records</h3>
<p>Finally, let’s consider subsection 72: “The operator of a regulated service must keep all records, including information and data, that are necessary to determine whether the operator is complying with the operator’s duties under this Act.”</p>

<p>Depending on how the Act is implemented, this could be quite burdensome to operators of small servers. <em>Even if</em> the Act sees fedi instances as independent, I don’t really see the benefits of my keeping records on all my decisions. Do I need to record the date and time every time I block an account or outside instance? Do I need to screenshot every time someone flags something?</p>

<h2 id="conclusion">Conclusion</h2>

<p>In my view, I completely understand the rationale behind the Online Harms Act: I believe corporate social media ought to be regulated. However, I am concerned that, in writing these regulations, the Act’s authors may place some undue burdens on the emerging fediverse, which is comprised of tens of thousands of small servers around the world. If the Act’s authors understand fediverse servers to be independent entities, then the Act <em>might</em> not be so burdensome. If the Act sees the fediverse itself as a large social media network, problems compound. I’m not a lawyer but I believe that the Act is more likely to have the former interpretation.</p>

<p>But even if so, the Act could still burden small, self-funded social media sites by asking already overworked moderators and admins to do more work (or hire/recruit someone specifically to deal with these regulations). If so, the Act’s burdens could happen at a bad time, because the fediverse is starting to emerge as a viable alternative to corporate social media – the very thing the Act is no doubt attempting to address.</p>]]></content><author><name>RWG</name></author><category term="Online Harms Act" /><category term="Mastodon" /><category term="Fediverse" /><summary type="html"><![CDATA[The Online Harms Act is currently the talk of Canada. As the government’s website describes it, The internet is an exceptional tool for people of all ages to learn, play and connect with family, friends and those with similar interests. However, just like the outside world, the digital world can pose significant dangers. Social media can be used to sexually exploit children, promote self-harm to children, incite violence, put people’s safety at risk and foment hate. Online harms have real-world impacts with tragic, even fatal, consequences. The Government of Canada has introduced legislation to hold social media platforms accountable for addressing harmful content on their platforms and for creating a safer online space that protects all people in Canada, especially kids. As something that addresses speech on the internet – and includes some strong penalties for spreading hate speech – the Act has led to massive debates. I won’t summarize them here, but you can read thoughtful critiques from Professor Michael Geist and you can listen to a discussion on Canadaland’s Backbench to get a sense of things. My interest here is not to delve into the controversies, but instead read the Act while wearing my Mastodon admin hat. I am one of the two admins of AoIR.social, a Mastodon instance for members of the Association of Internet Researchers. AoIR.social gives our members access to the fediverse – the global network of thousands of social media servers, with millions of users engaged in social media activities. An initial question: does the Act apply to the tens of thousands of fediverse instances with their millions of users? Does it thus apply to AoIR.social? Considering that the Act defines “social media service” as “a website or application that is accessible in Canada, the primary purpose of which is to facilitate interprovincial or international online communication among users of the website or application by enabling them to access and share content” (page 5), then the answer is yes. AoIR.social operates internationally, including in Canada. So do many of the other tens of thousands of fediverse servers. Since I’m one of the two admins of AoIR.social, am I affected? I believe so: I would be an “operator,” “a person that, through any means, operates a regulated service.” It could also be that the AoIR organization itself would be the operator, since in this Act “person” also applies to corporations. The Act would create a Digital Safety Commission, an agency that would govern social media services. The Act notes this Commission should consider things like the size of the service and the operator’s financial and technical abilities. This is good – many fediverse instances are small and are run by individuals or a handful of folks. They also often run on very small budgets as not-for-profit organizations. Regardless, however, I believe small fediverse servers would be affected (unless they find a way to not be available to Canadians). So: will the Act radically affect fediverse instances, such as AoIR.social? The Act specifically says our service should not harm freedom of expression, and reading it leads me to believe that AoIR.social won’t be affected in that manner. While we welcome debate and discussion, we’re not in the business of platforming the sorts of harmful content the Act discusses. But, the implementation of the Act could prove to be very burdensome to the administration of fediverse instances, such as AoIR.social. Much is going to hinge on how the Act understands the fediverse.]]></summary></entry><entry><title type="html">Researching the Fediverse: Instances and Individuals</title><link href="http://localhost:4000/2024/03/14/Instances-and-Individuals.html" rel="alternate" type="text/html" title="Researching the Fediverse: Instances and Individuals" /><published>2024-03-14T00:00:00-04:00</published><updated>2024-03-14T00:00:00-04:00</updated><id>http://localhost:4000/2024/03/14/Instances%20and%20Individuals</id><content type="html" xml:base="http://localhost:4000/2024/03/14/Instances-and-Individuals.html"><![CDATA[<p>I just read a new article focusing on Mastodon: Christina Dunbar-Hester’s “<a href="https://firstmonday.org/ojs/index.php/fm/article/view/13367/11436">Showing Your Ass on Mastodon</a>.” (I’ve put in <a href="/bib.html">the bibliography</a>, too). It has inspired a blog post!</p>

<p>Dunbar-Hester’s article discusses a controversy – and a harassment campaign – centering on the #asstodon hashtag on the fediverse. She created (or co-created) that hashtag in late 2022, not long after the large wave of people joined Mastodon due to Musk’s purchase of Twitter. The #asstodon hashtag was used predominantly to share pictures of donkeys. However, because of the double-meaning, there was at least one buttshot included in the mix.</p>

<p>In this paper, which is a kind of accidental autoethnography, Dunbar-Hester discusses how one donkeyposter become irate over the presence of human butts instead of donkeys in #asstodon posts. The donkeyposter eventually began harassing people – including Dunbar-Hester, using multiple accounts, posting racist content, and even emailing Dunbar-Hester at her work.</p>

<p>In researching donkeyposter’s actions, Dunbar-Hester argues that the structure of Mastodon may not be amenable to hashtag activism.</p>

<p>I should note the article has a delightful amount of butt puns! I only managed one in this post (see if you can find it).</p>

<p>I want to draw on Dunbar-Hester’s article to write about something I’ve been wrestling with: methodologies for studying the fediverse. Specifically, I want to highlight a distinction between Dunbar-Hester’s approach and the one I’ve chosen for my <a href="/2024/02/11/Move-Slowy-Preview.html">book project</a>. This is not to say Dunbar-Hester did it wrong – in fact, her paper is excellent, and as fediverse scholarship grows, we will need multiple studies and many perspectives. I will highlight my instance-centric approach as a contrast.</p>

<!-- more -->

<h2 id="the-individual-member-perspective">The Individual Member Perspective</h2>
<p>Dunbar-Hester notes multiple times she did not start out to do research on Mastodon (let alone the broader fediverse). Instead, like many folks, she came there after Musk bought Twitter. Like other academics, she worked to rebuild networks on Mastodon, using a hashtag (#commodon) to gather.</p>

<p>However, she gained a great deal of insight into Mastodon’s socio-technical politics when she started using/creating a whimsical #asstodon hashtag. The goal was to inject a bit of levity into the otherwise professional media studies community; she posted #asstodon with a picture of a donkey, and soon others followed suit. This replicates what other animal lovers have done – #dogsofmastodon is one of my favorite hashtags. And, sure, there are things for cats – even though cats are terrible pets.</p>

<p>Like many hashtags, this one somewhat escaped her control. In my book, I write about how #fediblock – a hashtag created by two women – was appropriated without credit by people building blocklists. The women, Marcia X and Ginger, have since gotten credit, but only after asserting their role in creating the hashtag.</p>

<p>In the case of #asstodon, the donkeyposter saw it as a chance to create “donkey content” on the network, sharing pictures of (their own? it’s not entirely clear) donkeys. The donkeyposter seems to have claimed the hashtag for their own, even going so far as to ask people to only use it for donkeys and not, inevitable as it was, human derrières. It seems that people did not listen to donkeyposter, who then began harassing folks for even suggesting that “ass” has multiple meanings. Dunbar-Hester came into donkeyposter’s sights when she agreed that “a thousand asses should bloom.”</p>

<p>In trying to get to the bottom of it all, Dunbar-Hester and some allies realized that there is a kind of <em>Rashomon</em>-esque quality to studying the fediverse. Trying to find out what set off the donkeyposter on a noncentralized network was difficult: posts were deleted, admins (rightfully) blocked the donkeyposter after that person degraded into racism and harassment, and the view from one instance is not the same as the view from another. Dunbar-Hester uses this insight to argue that hashtag activism will not function the same on Mastodon as it did on Twitter, because the latter, for all its faults, could centralized all hashtags and give people a more global view of them. Mastodon and the fediverse, in contrast, can only give a partial view – a “lossy” one, to use her term.</p>

<p>While she did not start out wanting to research Mastodon, there are few people more qualified to do this work: Dunbar-Hester is the author of two excellent books: <em><a href="https://mitpress.mit.edu/9780262534765/low-power-to-the-people/">Low Power to the People</a></em> focuses on community radio, and <em><a href="https://press.princeton.edu/books/hardcover/9780691182070/hacking-diversity">Hacking Diversity</a></em> focuses on diversity advocacy in FOSS communities. Mashing the two together – community media and FOSS – and you get tremendous insight into Mastodon and the fediverse. So when she flips the switch and investigates “donkeygate” on the fedi, she is well-equiped.</p>

<p>But, as she notes, she only makes claims from her own perspective. It’s the perspective of an individual Mastodon member – a valuable one, but a limited view.</p>

<h2 id="the-instance-perspective">The Instance Perspective</h2>
<p>Unlike Dunbar-Hester, I’ve explicitly set out to research Mastodon and the fediverse from day 1.</p>

<p>I’ve focused on a particular aspect of the fediverse: instance-to-instance relations. I’ve highlighted what I call (drawing on a <a href="https://www.tandfonline.com/doi/full/10.1080/1369118X.2022.2147400">paper co-authored with Diana Zulli</a>) the “covenantal” approach to network building, where the smallest unit is the group. I focus on the decisions to maintain or break federated connections, which means I spend a great deal of time analyzing the role of codes of conduct, blocklists, funding models, and hashtag coordination in building a network of instances.</p>

<p>I chose this because the fediverse is comprised of instances, and the act of making an instance is a political act – an instance admin must set policies, decide who should be allowed to sign up, and how long connections between instances should be maintained. Even if an admin shirks these things and says “anything goes,” that’s still a political decision.</p>

<p>And choosing an instance does require some effort – selecting one, agreeing to a code of conduct, and learning the ropes of a specific community. Even if someone chooses an instance at random, there’s still some demand that the person abide by norms. This is why I tend to use the term “member” instead of “user” for individual fediverse accounts.</p>

<p>I do focus on individual members in the book, particularly artists, mutual aid practitioners, and people who have shifted from Twitter. But by and large my view tends to put these individuals in relation with instances or larger instance-to-instance relations.</p>

<p>Overall, I privilege admins and moderators in my research. And this is a limitation of my own perspective. While I can see much from this view, it – like Dunbar-Hester’s – is not a view from nowhere. It is situated, as well.</p>

<h2 id="multiple-perspectives-needed">Multiple Perspectives Needed</h2>
<p>I contrast our approaches because they reveal ways forward for other researchers. Echoing Dunbar-Hester, I would also say: someone ought to write this up! More research on the fediverse is needed. My approach is not superior to Dunbar-Hester’s. I can see certain things, and she can see others. So, future researchers, be mindful of perspective.</p>

<p>Her approach provides valuable documentation and insight into what it’s like to be a skilled researcher coming to the fediverse. The individual, self-reflexive perspective Dunbar-Hester brings is incredibly important. It can inform work on human-computer interaction, masspersonal communication, and activism, among other things.</p>

<p>But as Dunbar-Hester found, it has limits: individuals can only get a partial view. In some ways, this is a good thing – I would be nervous if any one person could get a global view of the fediverse without the consent of network members. I don’t even think it’s wise for <em>researchers</em> to get a global view without the consent of members. At most, I would support a global view of instances, but not the ability to dive into any given individual account.</p>

<p>More importantly, if we stress individual perspectives, we run the risk of erasing instances. If the fediverse is a network of individuals who can interact without regard to the instance, than instance administration becomes a mere service and not a political act. (In some ways, I think Bluesky is going this direction, and I fear that such an approach replicates the eliding of things like moderation, much as corporate social media has done, hiding moderation practices behind layers of abstraction).</p>

<p>So what are the limitations of my more instance-centric view? Well, obviously, the perspective of individual members can get lost.</p>

<p>But more importantly, it puts a lot of weight on the admin’s perspective – and as <a href="https://www.ucpress.edu/book/9780520393943/governable-spaces">Nathan Schneider has argued</a>, this (crypto or explicit) valorization of the almighty sysadmin can lead to authoritarianism. The danger is that an instance becomes a pseudo-state, with the admin reigning supreme. Privileging the admin may not challenge this view. (I agree, to a point, but I would note that noncentralized instance-to-instance relations, as well as the ability to move instances, mitigate the power of individual admins to a large degree).</p>

<p>Ultimately, of course, Dunbar-Hester’s work doesn’t merely provide a foil for what I’m doing. Her conclusion is that activists need to influence the fediverse for more tools to make large-scale collective organizing possible. I agree. What those tools end up looking like – individual- or instance-centric – will shape the network to come, but in any case, the status quo may not be working well for activists.</p>]]></content><author><name>RWG</name></author><category term="Goal 2" /><summary type="html"><![CDATA[I just read a new article focusing on Mastodon: Christina Dunbar-Hester’s “Showing Your Ass on Mastodon.” (I’ve put in the bibliography, too). It has inspired a blog post! Dunbar-Hester’s article discusses a controversy – and a harassment campaign – centering on the #asstodon hashtag on the fediverse. She created (or co-created) that hashtag in late 2022, not long after the large wave of people joined Mastodon due to Musk’s purchase of Twitter. The #asstodon hashtag was used predominantly to share pictures of donkeys. However, because of the double-meaning, there was at least one buttshot included in the mix. In this paper, which is a kind of accidental autoethnography, Dunbar-Hester discusses how one donkeyposter become irate over the presence of human butts instead of donkeys in #asstodon posts. The donkeyposter eventually began harassing people – including Dunbar-Hester, using multiple accounts, posting racist content, and even emailing Dunbar-Hester at her work. In researching donkeyposter’s actions, Dunbar-Hester argues that the structure of Mastodon may not be amenable to hashtag activism. I should note the article has a delightful amount of butt puns! I only managed one in this post (see if you can find it). I want to draw on Dunbar-Hester’s article to write about something I’ve been wrestling with: methodologies for studying the fediverse. Specifically, I want to highlight a distinction between Dunbar-Hester’s approach and the one I’ve chosen for my book project. This is not to say Dunbar-Hester did it wrong – in fact, her paper is excellent, and as fediverse scholarship grows, we will need multiple studies and many perspectives. I will highlight my instance-centric approach as a contrast.]]></summary></entry><entry><title type="html">“Move Slowly and Build Bridges” Preview</title><link href="http://localhost:4000/2024/02/11/Move-Slowy-Preview.html" rel="alternate" type="text/html" title="“Move Slowly and Build Bridges” Preview" /><published>2024-02-11T00:00:00-05:00</published><updated>2024-02-11T00:00:00-05:00</updated><id>http://localhost:4000/2024/02/11/Move%20Slowy%20Preview</id><content type="html" xml:base="http://localhost:4000/2024/02/11/Move-Slowy-Preview.html"><![CDATA[<p>So… it’s coming together.</p>

<p>My current book, <em>Move Slowly and Build Bridges: Mastodon, the Fediverse, and the Struggle for Ethical Social Media</em> is mostly drafted! I am drafting a conclusion, but for now, I figured I would provide an overview of the book.</p>

<p>This post gives a chapter-by-chapter summary of the draft. Since it’s a draft, things can still change, but as of today, I’m pretty pleased with the structure.</p>

<!-- more -->

<h2 id="introduction">Introduction</h2>
<p>The introduction gives a bit of background on the fediverse and justifies a focus on Mastodon. I also discuss the history of alternative social media – activists have been trying help us move past corporate social media for a long time. I define terms used throughout the book, like “noncentralization” and “covenantal fediverse.”</p>

<h2 id="chapter-1-from-techlash-to-alternative-or-how-to-vaporize-elon-musk">Chapter 1: From Techlash to Alternative, or How to Vaporize Elon Musk</h2>
<p>This chapter answers a key question: what pushes people to leave corporate social media? We’ll look at the recent purchase of Twitter by Elon Musk, which prompted millions of people to leave Twitter and switch to Mastodon and the broader fediverse. What does it look like to flee corporate social media for a noncentralized alternative? And, since Mastodon instances are often run by volunteers, and what does it look like to deal with a wave of new members? And what does it mean to offer an “alternative”? Drawing on interviews with many people affected by Musk, the chapter contrasts the actions of a single billionaire with communities of people helping each other.</p>

<h2 id="chapter-2-the-non-standard-standard-when-activitypub-met-mastodon">Chapter 2: The Non-Standard Standard: When ActivityPub met Mastodon</h2>
<p>Chapter 2 focuses on the technical achievement of noncentralization. Based on interviews, it tells the  a key protocol, ActivityPub, and the queer and trans developers who created it in spite of a series of obstacles. It turns out that the ActivityPub authors were creating something desperately needed by a then-unknown project called Mastodon, which was trying to find a way to provide protections for marginalized members in an internet culture that demanded total transparency. In turn, Mastodon provided a boost to the creators of ActivityPub by using a beta version of the protocol. (I talk about an early version of this chapter in a <a href="/2023/10/15/APnonStandard.html">previous blog post</a>.)</p>

<h2 id="chapter-3-codes-of-conduct">Chapter 3: Codes of Conduct</h2>
<p>This chapter discusses the social contract shared among many Mastodon moderators. Mastodon is a system comprised of many small servers. You could take its code and install it on your computer, but thanks to ActivityPub, your computer can talk to other Mastodon computers around the world. With all these different Mastodon servers running, how is social coordination possible? The answer is codes of conduct. Championed by trans technologist Coraline Ada Ehmke (interviewed for this project) in the mid-2010s, codes of conduct add a social layer to networking technologies. With codes of conduct, Mastodon moderators can make decisions about connecting to one another while promoting the safety of their communities. In addition, codes of conduct are not concocted by corporate lawyers, but are democratically made by the community, for the community. Thus, Mastodon and the fediverse is more than just a technical achievement – it’s a social one, as well.</p>

<h2 id="chapter-4-rage-and-joy-playvicious-fediblock-the-badspace-and-the-politics-of-defederation">Chapter 4: Rage and Joy: Playvicious, #Fediblock, the BadSpace, and the Politics of Defederation</h2>
<p>This one builds on the previous chapter by telling the story of how Mastodon and the fediverse decide when to block, rather than connect, to another server. What happens when an entire portion of the network trolls, harasses, and misinforms the rest? The recourse Mastodon members have is to block them. But making the decision to block a server is not a straightforward one. The story can be told through the experiences of Black fediverse members, such as Ro and Marcia X. Ro is currently building The Bad Space, a mechanism to easily share blocklists across the fediverse. His work builds on that of his friend, Black feminist Marcia X, who has engaged in hashtag activism, making the now ubiquitous #fediblock hashtag. Both The Bad Space and #fediblock have been criticized as inimical to federation, but the experiences of Black Mastodon members shows us that we need to have these tools – and that we have to do the hard work of collectively making blocking decisions – if we want to have a thriving and anti-racist fediverse.</p>

<h2 id="chapter-5-paying-for-it-the-fediverses-alternative-economies">Chapter 5: Paying for It: The Fediverse’s Alternative Economies</h2>
<p>Chapter 5 addresses a question I always get when I talk about the fediverse: who pays for it? After 20 years of corporate social media and surveillance capitalism, we have forgotten that there are other economic models for digital media. The chapter explores the non-capitalist elements of the fediverse, including the use of donations and non-profit organizations to fund servers, mutual aid between fediverse members, and how artists and musicians use the network to promote their work. Together, these folks are forging an alternative not just to corporate social media, but to capitalism itself.</p>

<h2 id="chapter-6-to-finity-and-before-degrowth-solarpunk-and-environmentalist-experiments-on-the-fediverse">Chapter 6: To Finity and Before: Degrowth, Solarpunk, and Environmentalist Experiments on the Fediverse</h2>
<p>This chapter focuses on the ecological impact of social media. While we’re encouraged to think of corporate social media as being a slick, clean, even immaterial system, in reality data storage and processing take a tremendous toll on resources. If the fediverse is to be a true alternative, we have to rethink how social media affects the environment. This chapter introduces us to degrowth thinkers and solarpunks who are using fediverse technologies to mitigate the climate disaster.</p>

<h2 id="chapter-7-threads">Chapter 7: Threads</h2>
<p>This one considers the corporate reaction to the fediverse. The fediverse is expanding, and thus it’s attracting the attention of corporate social media, which has traditionally simply bought out the competition, or had it regulated away. The latest to try is Meta, the owner of Facebook, Instagram, and WhatsApp. In early 2023, Meta announced that their latest project, a Twitter-like system called “Threads,” would adopt ActivityPub and thus be able to federate with Mastodon and fediverse instances. This chapter focuses on the #fedipact, a campaign started by a trans woman by the name of vanta black who is leading a  resistance to Meta’s effort to federate.</p>

<h2 id="conclusion">Conclusion</h2>
<p>This is the part I’m still drafting. I’m taking the “ethical” seriously in the subtitle and thinking through ethical theories and the fediverse. In addition to being inspired by the great people I’ve met doing the research for the book, this part was also inspired by <a href="/2023/11/22/EthicsAndCOCs.html">a class exercise I did with students</a> in my recent Media Ethics class. More to come about this chapter…</p>

<h2 id="lets-talk">Let’s Talk!</h2>
<p>If you like what you see here, let’s talk! I’m looking to talk about this project with podcasters and journalists, not to mention students and other researchers. The biggest thing I’ve learned about the fediverse is that people can, in fact, change media for the better. It’s a struggle, but it can be done. I want to share this with others, and also I hope this work inspires more academic and journalistic engagement with the fediverse. To paraphrase Captain Picard, I think we’re only at the beginning of the adventure.</p>]]></content><author><name>RWG</name></author><category term="Goal 2" /><category term="Move Slowly and Build Bridges" /><summary type="html"><![CDATA[So… it’s coming together. My current book, Move Slowly and Build Bridges: Mastodon, the Fediverse, and the Struggle for Ethical Social Media is mostly drafted! I am drafting a conclusion, but for now, I figured I would provide an overview of the book. This post gives a chapter-by-chapter summary of the draft. Since it’s a draft, things can still change, but as of today, I’m pretty pleased with the structure.]]></summary></entry><entry><title type="html">Thoughts on Threads, or Is Mark Zuckerberg Jesus?</title><link href="http://localhost:4000/2023/12/16/ThoughtsThreads.html" rel="alternate" type="text/html" title="Thoughts on Threads, or Is Mark Zuckerberg Jesus?" /><published>2023-12-16T00:00:00-05:00</published><updated>2023-12-16T00:00:00-05:00</updated><id>http://localhost:4000/2023/12/16/ThoughtsThreads</id><content type="html" xml:base="http://localhost:4000/2023/12/16/ThoughtsThreads.html"><![CDATA[<p>(Sorry about the provocative title, but I just had to do it.)</p>

<p>Today, a lot of people have thoughts on Threads, which is <a href="https://techcrunch.com/2023/12/14/mastodon-founder-touts-threads-federation-saying-it-makes-his-x-rival-a-far-more-attractive-option/">actively testing ActivityPub federation</a>. The reactions range from triumphant proclamations about this making the fediverse more legitimate to abject horror that a company so reviled is attempting to join the fedi.</p>

<p>Full disclosure: I’m more in the latter camp.</p>

<p>As readers of this blog know, I’m working on a <a href="/2023/08/17/OxfordUP.html">book about the fediverse</a>, and part of my process is to share ideas out in the open. Since any book about the fediverse will have to talk about Threads, I figured this might be a good place to share a rough idea of how a chapter about Threads might go. Comments are welcome, of course!</p>

<p>Away we go…</p>

<!-- more -->

<h2 id="recapitulation">Recapitulation</h2>
<p>There’s a term I heard a few months back, a bit by accident: “recapitulation.”<a href="#note1">[1]</a> I’ve been been rolling it around in my mind, like a marble in the palm of the hand. It’s so generative.</p>

<p>And today, as Meta’s Threads starts the long-awaited (or long-feared) process of federating via ActivityPub, I think I have a way to pick apart what’s going on with this term.</p>

<p>After all, “recapitulation” is a kind of keyword in the sense <a href="https://en.wikipedia.org/wiki/Keywords:_A_Vocabulary_of_Culture_and_Society">Raymond Williams meant</a>: a term that has multiple, contested meanings, meanings that are bound up with multiple problems. Look it up in the Oxford English Dictionary and you’ll find three ways “recapitulation” helps us pick apart Meta’s Threads and the fediverse:</p>
<ul>
  <li>a Christian theological meaning, where all of human history is recapitulated by Jesus Christ,</li>
  <li>a summing up of previous arguments, and</li>
  <li>a unificiation.</li>
</ul>

<p>Let’s take a look at each in turn.</p>

<h2 id="theological-recapitulation">Theological recapitulation</h2>
<p>According to the Oxford English Dictionary, the theological meaning of “recapitulation” dates back at least to 1629: “the summing up and redemption of all human experience in the life and death of Christ.” In this <a href="https://www.pharosjot.com/uploads/7/1/6/3/7163688/article_1_vol_101__2020_.pdf">theological theory</a>, Jesus Christ is a second Adam, one who did not sin. In delivering the rest of us from sin, human history from the Fall of Adam to the present is summed up under the name of Christ. Our acceptance of Christ allows for a return to pre-lapsarian life.</p>

<p>Ok, what the hell does that have to with Threads?</p>

<p>Well, let me drop a few quotes from coverage of Threads:</p>

<ul>
  <li>Kalhan Rosenblatt, <a href="https://www.nbcnews.com/tech/threads-meta-twitter-rival-app-reaction-nostalgia-chaos-rcna92867">writing for NBC</a>: “Threads has been chaotic yet blissful, users said, noting the app reminded them of the early days of the internet — especially since ads have yet to hit the platform.”</li>
  <li>Tamara Palmer, <a href="https://48hills.org/2023/07/threads-vs-twitter-look-ma-no-nazis-yet/">writing in 48Hills</a>: “Threads has a much lighter and nostalgic feel than Twitter at the moment; I even got to, um, Thread with a Vanderpump Rules star last night. (They’re just like us!) It almost feels like 2006 again.”</li>
  <li>Jay Clouse, <a href="https://creatorscience.com/">writing in Creator Science</a>: “For the last several days, I’ve actually published more on Threads than anywhere else. And not because I’m chasing an opportunity – because it was more fun for me!”</li>
  <li>Kari Paul, <a href="https://www.theguardian.com/technology/2023/jul/06/we-tried-threads-metas-new-twitter-rival-heres-what-happened">writing in the Guardian</a>: “As a tech writer who has reported extensively on the privacy concerns surrounding Meta, the company’s shameless copying of competitors’ apps, and tech’s growing unchecked power, it pains me to say that I actually enjoyed using Threads.”</li>
</ul>

<p>There’s a clear theme here: nostalgia for a more fun time online. It’s a time before something awful ruined it all. The nostalgic tone becomes even clearer when we consider the context: Threads started not long after Elon Musk purchased Twitter and turned it into a hellscape.</p>

<p>Across much of the coverage of Twitter alternatives (including Bluesky and, to be fair, Mastodon), there’s a sense that the new thing is a return to a better, lost time. For some, it was Twitter before #gamergate. For others – I think journalists fall in this camp – it’s a time when they had authority and were respected. For others, it’s Twitter before Donald Trump. And for everyone, it’s Twitter before Musk.</p>

<p>Astute readers will see where I’m going with this: Mark Zuckerberg is here to cleanse us of our sins and take us back to the Garden of Microblogging Eden. Or I should put it like this: Meta, a major social media corporation, is swooping in to make microblogging great again.</p>

<p>Zuckerberg – or maybe Meta – is Jesus.</p>

<p>(I apologize if those last few sentences made you want to smash your phone or computer against the wall.)</p>

<p>As Meta federates via ActivityPub, this sort of nostalgia might get amplified. If we could only return to Twitter before the Fall, many people seem to be saying. Who will lead us there?</p>

<h2 id="repetition-of-the-argument">Repetition of the argument</h2>
<p>So that’s one meaning of recapitulation. But of course, it’s not the only one, and probably not the first one most readers thought of.</p>

<p>The most common meaning is (again, per the OED) “The action or an act of recapitulating (something); a brief restatement or repetition; a summing up; a summary.” This is where we get the term “recap,” a restatement, a summary form of an argument or plot. (It’s also used in music in sonatas, – the repetition of a melody). The verb form is “to go through or repeat again, usually in a more concise manner; to go over the main points or substance of (an argument, statement, etc.); to summarize, restate briefly.”</p>

<p>When it comes to Meta and the fediverse, oh, yeah – there are a lot of repeated arguments happening.</p>

<p>As <a href="https://www.youtube.com/watch?v=yZoASOyfvGQ">Derek Caelin has documented</a>, the fediverse went through a massive debate when another large entity attempted to federate. That entity was Gab.com, a white Christian nationalist social networking site. Or, if you prefer, a Nazi site, since it does host self-described Nazis.</p>

<p>It should have been easy to block Gab. However, while the story told about Gab today is that it was defederated quickly, people who lived through that period note how much benefit of the doubt Gab got. The counter-argument against blocking Gab was pretty simple: openness and free speech. That is, rather than preemptively blocking them, this argument goes, we should give them a chance. Ours is an open network. When they say racist stuff, we should counter it with rational, anti-racist arguments. If any of their users are truly bad actors, we will eventually see evidence of it, and then we can block those users. If after a period of time it turns out that the whole domain is a bad actor, then block them.</p>

<p>Basically, let them join, see how they act, and then block. That sort of thing.</p>

<p>It’s a naive view of free speech that critical theorist Herbert Marcuse would call <a href="https://www.marcuse.org/herbert/publications/1960s/1965-repressive-tolerance-fulltext.html">“repressive tolerance.”</a> As Marcuse argues, if we tolerate dominant ideas (e.g., white supremacy, transphobia), then we effectively eradicate marginalized ideas.</p>

<p>Those who argued for preemptively blocking Gab recognized this. Rather than allowing for self-described Nazis to spout hate, the Gab-blockers rejected the free speech and openness argument in favor of supporting marginalized people so <em>they</em> could have a chance to speak. Because spaces for the marginalized to speak are rare.</p>

<p>Those who called for preemptive blocking were called tyrants, because they would violate the sanctity of openness and free speech. The naive free speech view, while naive, is powerful in its simplicity.</p>

<p>Fast forward to today: we’re recapitulating that debate.</p>

<p>Back in June or so, vanta black created <a href="https://fedipact.online/">the Fedipact</a>, asking admins to preemptively block Threads (full disclosure, my instance is on the list). Why? Well, <a href="https://fedipact.online/why">I’ll just quote her</a>:</p>
<blockquote>
  <ul>
    <li>that time [Meta] helped facilitate a genocide</li>
    <li>that time they helped try to rig an election</li>
    <li>that time they did creepy behavioral experimentation on their users</li>
  </ul>
</blockquote>

<p>We could add more to vanta’s list: Meta platforms hate speech (Libs of Tiktok is often invoked here). Instagram has a destructive influence on teen girls’s sense of worth. Meta attempts to moderate globally on the cheap with underpaid laborers (who get crushed when they try to unionize for their rights).</p>

<p>And none of this is to mention the idea that prompted my whole academic career back in 2008: on Meta properties, we do the free work of declaring what we like, and then Meta sells our attention to advertisers.</p>

<p>So, blocking Meta’s Threads should be easy, right?</p>

<p>It turns out, not so much. Fedipact has received a lot of criticism. Other people have summed up (or made) the arguments in favor of not blocking Meta, so I won’t exhaustively recap them, but here are the big ones:</p>
<ul>
  <li>It will be good for ActivityPub,</li>
  <li>It will legitimate the fediverse,</li>
  <li>It will allow fediverse members to increase their follower counts, or</li>
  <li>of course: free speech and openness</li>
</ul>

<p>In spite of all the well-documented, terrible, awful, horrifying things that company has done, <em>we are recapitulating the same conflict we saw with Gab.</em> Just like Gab, Meta’s Threads is also getting a great deal of benefit of the doubt.</p>

<p>It’s just that this time, there feels like a lot more is at stake.</p>

<h2 id="unification">Unification</h2>
<p>What do we do about this? Where do we go from here?</p>

<p>Well, let’s look at a third (and admitedly obscure) meaning of “recapitulate”: “to come together into one.”</p>

<p>At first glance, this is the great fear that Meta’s Threads invokes. In my book, I’m arguing that Mastodon and the fediverse are a noncentralized system. Not <em>decentralized,</em> but <em>noncentralized</em>. By that I mean the fediverse is actively resistant to centers. For example, if an instance gets to be too big – Mastodon.social comes to mind – people start openly critiquing it, arguing folks should move accounts from it. So much of the structure of the fediverse, from its open protocols to its FOSS code to its cultural practice, is about noncentralization.</p>

<p>But with Meta in town? The fear is that this massive corporation will absorb the fediverse. It could do so in many ways: taking over the ActivityPub protocol. Drawing many of the most popular accounts away from the rest of the fedi and onto Threads. Overwhelming the fediverse with marketer and influencer content. Swamping the fedi with disinformation, conspiracy theories, and hate speech.</p>

<p>But maybe the third meaning of “recapitulation” shows us a way out.</p>

<p>What if the coming together into one, the recapitulation of the fediverse, is to unify – once again – against an unethical actor? I noted that the defederation of Gab wasn’t a simple thing, but it did happen.</p>

<p>Elsewhere, <a href="https://www.tandfonline.com/doi/full/10.1080/1369118X.2022.2147400">a colleague and I argued</a> that the emergent, shared ethical core of the fediverse represents a digital covenant. As instances develop their distinct codes of conduct, and as they federate, we see an emergent, shared, global-yet-thin set of deontological rules about content moderation.</p>

<p>The fediverse in 2023, I would argue, is an even stronger covenantal network than it was in the Gab days. Let’s look at what’s going on: Fedipact. #Fediblock. Communal blocklists. The Mastodon Server Covenant. There is a shared ethical core on the fediverse, and it is possible that this unity-through-federation could be successful in fending off Meta.</p>

<p>This is why the third meaning of recapitulation is my favorite. Because it’s not nostalgic or atavistic. It’s not about a sole figure (or a sole corporation) saving us. It’s not a rehash of an argument we endlessly have. It’s about unifying. And the fediverse could do the seemingly impossible: unifying through heterogeneity.</p>

<p>A noncentralized unity.</p>

<h2 id="notes">Notes</h2>

<p><a name="note1">[1]</a> My digging into the concept of recapitulation happened by accident. One of my interviewees used it to refer to how mainstream culture absorbs alternative practices. As a commenter on the fediverse noted, my interviewee most likely meant to say “recuperation”, a <a href="https://en.wikipedia.org/wiki/Recuperation_(politics)">term of art from the Situationists</a>. Based on the context of the interview, I would say this is the case. I’ve edited this post to reflect this to respect the fact that my interviewee probably didn’t intend me to interpret him that way.</p>

<p>I now consider this take on Threads to be the product of a happy accident, since looking at recapitulation led me to the idea of some savior coming to take us back to a lost time. I think the narrative around Threads outside of the fedi has been about nostalgia. I <em>definitely</em> think the narrative about Bluesky has been about nostalgia. Even the discourse about Mastodon in its early days was about that.</p>

<p>And I also like the idea of a unification-through-difference that the third meaning implies.</p>

<p>However, I don’t think this post will form the basis of the chapter of the book. Some ideas will travel from it – including some ideas based on the feedback I got on the fedi – but this recapitulation idea is a bit too convoluted to make it into my book, which is intended for a broad audience.</p>]]></content><author><name>RWG</name></author><category term="Meta" /><category term="Threads" /><category term="digital covenant" /><summary type="html"><![CDATA[(Sorry about the provocative title, but I just had to do it.) Today, a lot of people have thoughts on Threads, which is actively testing ActivityPub federation. The reactions range from triumphant proclamations about this making the fediverse more legitimate to abject horror that a company so reviled is attempting to join the fedi. Full disclosure: I’m more in the latter camp. As readers of this blog know, I’m working on a book about the fediverse, and part of my process is to share ideas out in the open. Since any book about the fediverse will have to talk about Threads, I figured this might be a good place to share a rough idea of how a chapter about Threads might go. Comments are welcome, of course! Away we go…]]></summary></entry><entry><title type="html">Ethics and Codes of Conduct on Mastodon</title><link href="http://localhost:4000/2023/11/22/EthicsAndCOCs.html" rel="alternate" type="text/html" title="Ethics and Codes of Conduct on Mastodon" /><published>2023-11-22T00:00:00-05:00</published><updated>2023-11-22T00:00:00-05:00</updated><id>http://localhost:4000/2023/11/22/EthicsAndCOCs</id><content type="html" xml:base="http://localhost:4000/2023/11/22/EthicsAndCOCs.html"><![CDATA[<p>Yesterday, I taught one of the final meetings of my undergrad “Ethics and the Media” course at York. We’re using <a href="https://bookshop.org/p/books/digital-media-ethics-charles-ess/7513541?ean=9781509533428">Charle Ess’s <em>Digital Media Ethics</em> (3rd edition)</a> as our textbook, and so we’ve had a good guide to ethical theories, such as virtue ethics, deontology, utilitarianism, and feminist ethics of care. (I also supplement Ess with readings and ideas from Shannon Vallor, Kwame Gyekye, Carissa Veliz, Michael Zimmer, and others).</p>

<p>Much of the course has been about learning the ethical theories and then discussing <a href="https://mediaengagement.org/vertical/media-ethics/">case studies</a>. It’s been quite an enjoyable course to teach, particularly because I’ve seen the students go from the vague and intellectually unsatisfying statement “Ethics is a subjective, personal thing” to the more robust “Let me lay out how a virtue ethicist would think about this.”</p>

<p>But I wanted to have at least one day of the course dedicated to applied ethics. Instead of looking at a case that happened in the past, I wanted the students to apply the ethical theories to a concrete situation.</p>

<p>And these days, we have a great situation in digital media ethics to consider: what to do when we start up a Mastodon server?</p>

<p>In this post, I’ll write up what we did in the class, in case anyone out there wants to try something similar.
<!-- more --></p>

<h2 id="mastodon-in-the-classroom">Mastodon in the classroom</h2>

<p>I spun up a relatively inexpensive Digital Ocean server and installed the latest version of Mastodon. I also imported a <a href="https://thebad.space">server blocklist</a>, because I did not want to have the students – all of whom were new to Mastodon – experience some nasty trolling in their first foray. At the same time, I still wanted students to be able to follow accounts outside of our server, so blocking known bad instances made the most sense. I recommend anyone using Mastodon in the classroom do something similar.</p>

<p>I then invited students to join and mess around with our server – post, share, make profiles, etc. I realized that they would see essentially an empty stream and few others – this is all part of the process. I wanted to stress to them that everything on the server is under our control, so we – not some big company – have to decide how active our server would be.</p>

<h2 id="what-about-a-code-of-conduct">What about a Code of Conduct?</h2>

<p>One step I skipped in setting up was setting server rules and a code of conduct. I did this on purpose: it was the point of the in-class discussion. After providing some background details about Mastodon and the fediverse and answering student questions, we then discussed codes of conduct. For background, I gave them a draft chapter of my <a href="/2023/08/17/OxfordUP.html">current book</a>, which focuses on the history of codes of conduct (and thus draws heavily on an interview with <a href="https://where.coraline.codes/">Coraline Ada Ehmke</a>).</p>

<p>After we talked codes of conduct, I talked about how running Mastodon requires us to be active in making choices about content moderation. Running a Mastodon server is a moment of applied ethics.</p>

<p>I then asked them to break into four groups:</p>

<ul>
  <li>One group focusing on <strong>feminist ethics of care,</strong></li>
  <li>Another focusing on <strong>deontology,</strong></li>
  <li>Another on <strong>virtue ethics,</strong></li>
  <li>And the last on <strong>utilitarianism.</strong></li>
</ul>

<p>I asked the group to first summarize the ethical theory (not an easy task, I know).</p>

<p>Next, I asked them to apply the ideas from their ethical theory to our potential Mastodon code of conduct.</p>

<p>I really, really liked the results!</p>

<p>Here are summaries of each:</p>

<h3 id="feminist-ethics-of-care">Feminist ethics of care</h3>
<p>Feminist ethics of care (FEOC) rejects the idea (most associated with deontology) that ethical decisions are the sole purview of individual, autonomous rational actors. Instead, FEOC argues we make ethical choices based upon, and informed by, relationships we have with one another. Moreover, an ethical choice is not purely a rational matter, but also involves emotions. Finally, FEOC elevates care of others to the center (but it rejects the idea that only one segment of our society is responsible for care work).</p>

<p>Based on this theory, the students argued that our Mastodon server code of conduct should</p>
<ul>
  <li>Describe how we can network with other servers who share our values.</li>
  <li>Take inspiration from the first clause of Canadian charter: your rights end where someone else’s begin. You can post so long as you don’t violate others’ rights.</li>
  <li>Emphasize contextual judgement (considering potential violations in context).</li>
  <li>Emphasize communication during moderation, using empathy for would-be violators.</li>
</ul>

<p>My take: this is a great set of insights. It echoes what I’ve learned over the past few years doing interviews with fediverse admins. Many told me that their approach to moderation is to talk to people and find out what’s going on. They also talk about how they choose to federate/block other instances.</p>

<h3 id="deontology">Deontology</h3>
<p>Deontology emphasizes individual rights and autonomy, as well as duties to do what is right. Intentions often matter more than consequences. Often deontology is expressed as rules (although that’s a bit reductive.)</p>

<p>Students in this group did offer rules, likely inspired by reading sample Mastodon codes of conduct:</p>
<ul>
  <li>Post nothing illegal!</li>
  <li>No discrimination based on age, race, gender, sexuality</li>
  <li>No harassment</li>
  <li>No trolling</li>
  <li>No defamation or coercion</li>
  <li>Show some respect in the community</li>
</ul>

<p>My take: if there’s one ethical theory that Mastodon seems designed for, it’s deontology. Mastodon’s software prompts the admin to put in “Server Rules,” short statements about expectations would-be members should live up to. Many, many Mastodon codes of conduct have rules similar to the above.</p>

<h3 id="virtue-ethics">Virtue Ethics</h3>
<p>Virtue ethics is less about intentions or consequences than it is about character. Virtues in a digital environment might include honesty, humility, courage, and compassion, and these are balanced against vicious extremes. Virtue ethics is also relational in that we teach children about virtues and provide advice to them when they have to make ethical choices.</p>

<p>The students in this group suggested that our code of conduct should</p>
<ul>
  <li>Call for displays of virtous traits, such as wisdom, courage, loyalty,</li>
  <li>Emphasize being polite and respectful, and</li>
  <li>Have high standards for moderation.</li>
</ul>

<p>My take: I was really curious what the students would say in this group, and they delivered some good stuff. What’s useful, I think, is contrasting the negative rules of deontology with these positive virtues and character traits. I could imagine a code of conduct that integrates virtue ethics to emphasize positive behaviors.</p>

<h3 id="utilitarianism">Utilitarianism</h3>
<p>Alongside another consequentialist theory, libertarianism, utilitarianism is probably the most familiar theory to me, since I grew up in the USA. (I’m not saying I endorse either; just that I think I soaked in them). Utilitarianism judges acts based on their consequences: if an act creates the greatest happiness for the greatest number of people, it’s an ethical one.</p>

<p>Students in this group emphasized the greatest happiness principle in their code of conduct ideas:</p>
<ul>
  <li>Let’s promote inclusivity to make people safe, welcome, and heard.</li>
  <li>We need to listen to user feedback.</li>
  <li>We need to consider well-being of the community.</li>
  <li>Server members should report stuff to the moderators.</li>
  <li>We should promote free speech but exclude hate speech.</li>
</ul>

<p>My take: Students really leaned into thinking about the would-be Mastodon server as a community, and so this approach emphasized group happiness. I think this was a good addition to the other ideas, because social media can be fun and happy – why not build a code of conduct that emphasizes these aspects?</p>

<h2 id="summing-it-all-up">Summing it all up</h2>

<p>We concluded the class by considering how these different approaches to a code of conduct could be synthesized. We kinda ran out of time for that, but I think we may have been able to write a pretty sweet code if we had more time.</p>

<p>I did spend some time talking about enforcement, since no code of conduct is worth anything if you’re not willing to live up to it. I ran various scenarios past them – what if someone outside our server violates our code? What if someone outside our server reports one of our members?</p>

<p>Their answers reflected the ideas I’ve heard from seasoned admins, including how admins discuss things with one another and how admins talk to members.</p>

<p>All in all, I think this experiment was really exciting. Unlike corporate social media – Facebook, TikTok, X, etc – <em>we</em> get to make decisions about moderation when we run our own instance. It’s a big responsibility, but these students showed they’re up for it.</p>]]></content><author><name>RWG</name></author><category term="Goal 2" /><category term="Mastodon" /><category term="Codes of Conduct" /><summary type="html"><![CDATA[Yesterday, I taught one of the final meetings of my undergrad “Ethics and the Media” course at York. We’re using Charle Ess’s Digital Media Ethics (3rd edition) as our textbook, and so we’ve had a good guide to ethical theories, such as virtue ethics, deontology, utilitarianism, and feminist ethics of care. (I also supplement Ess with readings and ideas from Shannon Vallor, Kwame Gyekye, Carissa Veliz, Michael Zimmer, and others). Much of the course has been about learning the ethical theories and then discussing case studies. It’s been quite an enjoyable course to teach, particularly because I’ve seen the students go from the vague and intellectually unsatisfying statement “Ethics is a subjective, personal thing” to the more robust “Let me lay out how a virtue ethicist would think about this.” But I wanted to have at least one day of the course dedicated to applied ethics. Instead of looking at a case that happened in the past, I wanted the students to apply the ethical theories to a concrete situation. And these days, we have a great situation in digital media ethics to consider: what to do when we start up a Mastodon server? In this post, I’ll write up what we did in the class, in case anyone out there wants to try something similar.]]></summary></entry><entry><title type="html">How Universities Lost the Internet</title><link href="http://localhost:4000/2023/11/10/HowUniversitiesLostIT.html" rel="alternate" type="text/html" title="How Universities Lost the Internet" /><published>2023-11-10T00:00:00-05:00</published><updated>2023-11-10T00:00:00-05:00</updated><id>http://localhost:4000/2023/11/10/HowUniversitiesLostIT</id><content type="html" xml:base="http://localhost:4000/2023/11/10/HowUniversitiesLostIT.html"><![CDATA[<p>My first full-time academic job was at the University of Utah. Utah is, of course, very famous. No, not because of <a href="https://en.wikipedia.org/wiki/Stanley_Pons">cold fusion</a> or teaching Ted Bundy about the law.</p>

<p>It is famous because it was the <a href="https://it.utah.edu/node4/posts/2017/august/node4-history.php">fourth node on the ARPAnet</a>, the forerunner to the modern internet. The other three nodes were in California; connecting to Utah was a major test of the network’s ability to work across long distances.</p>

<p>Although it was a US Defense Department-funded project, the ARPAnet was a <a href="https://ieeexplore.ieee.org/document/5432117">playground for academics</a> who took its mission (command-and-control even in spite of a nuclear attack) and turned it into research into networking and collaboration. The pattern continued: academic exploration of computer technologies has produced a bewildering array of experiments, and no doubt students at institutions have benefited greatly from being able to play with local, experimental computer tools while they study.</p>

<p>Fast forward to the early 2010s. I’m working at Utah, hired in part to teach a Web design class to Communication majors. Simple enough: each and every person affiliated with Utah had their own domain (something like domain.utah.edu/~username) on a local server, complete with FTP access via their email credentials. I taught students the basics of HTML and CSS. I got to see students who were openly scared of coding make things that appeared on their screens – and on the internet. It was fun!</p>

<p>Until it was not. I was at Utah from 2010 to 2020. Over that time, it became harder and harder to get students into their web space. It turns out that Utah was winding down web hosting for everyone, centralizing its web presence and no longer providing web space to anyone. To support our class, the IT folks helpfully carved out some space on a server, specifically for our Comm Intro to the Web Design students, but we knew this was an exception.</p>

<p>At the end of my time there, even the machines in the computer lab were outsourced. Instead of fully-functional desktops, students were accessing their servers over a convoluted “thin client” computer lab setup. I had to spend the first 2 weeks just showing them how to find their files – since they were no longer local – and then FTP into a server to move those files over a client-to-cloud-to-FTP setup. This was for students who had no networking or web design experience – it was <em>rough</em>. (And if we needed software – such as basic text editor – good luck getting it when all the software was on a cloud somewhere).</p>

<p>I’m sorry to say I spent a great deal of that time in an increasingly adversarial relationship with the IT folks.</p>

<p>As this happened, my colleague <a href="https://seanlawson.net">Sean Lawson</a> and I would vent our frustration by jokingly saying, “Welcome to Node 4!” The irony being that Utah was once <em>25% of the freakin’ Internet</em> but we could not get easy access to basic Web hosting. It was an ordeal just to get students to the point where they could move a text file they were working on to a server.</p>

<p>Fast forward to today. Now, I am happily employed by York University in Toronto. But just the other day, my colleagues met for a faculty meeting, and we discussed recruiting students. Someone suggested we post information about our faculty to our department website and social media. “No,” the chair said. “All of that would have to go through the central administration” – the implication being either it wouldn’t be allowed, or that it would take months to achieve.</p>

<h2 id="someones-gotta-write-this-book">Someone’s Gotta Write This Book</h2>

<p>I would propose, were I to have time, to write a book called “How Universities Lost the Internet.” How did we get from many nodes to everything being dumped into California or Redmond, WA? How did we get from a system of experimentation to seeing digital media as a controlled environment to market a brand? How did we get to the point where university core functions were run by for-profit firms?</p>

<p>It would be a fascinating book. (Someone else can write it, though; I’m too busy with <a href="/2023/08/17/OxfordUP.html">my current project</a>!)</p>

<!-- more -->

<p>I think there’s quite a readership for this book, judging from a recent thread on the fediverse. I posted this <a href="https://aoir.social/@rwg/111308895829845440">proposed book idea on Mastodon</a> a few days back:</p>

<blockquote>
  <p>Does this book exist? “How Universities Lost the Internet”?
Or has someone done research on this topic? That is, the fact that many North American universities have ceded all technical capacity to Microsoft, Google, etc?
It used to be students could get web hosting, email, and even some cool experimental online stuff through their schools. Now every online communication channel is locked down.</p>
</blockquote>

<p>The response to my fediverse post was pretty intense. I’m not going to directly quote any of it here because I did not ask permission of the respondents (and of course you can see public comments if you follow the above link), but I will sum things up:</p>

<ul>
  <li>University IT is being outsourced across the board. Instead of local email, storage, or HR systems, these services are subdomains of a corporate site, e.g., https://yorku.zoom.us/, or even just simply note affiliated with the university at all (e.g., when I login to York webmail, the domain is office.com and there is no York branding).</li>
  <li>This is a global phenomenon. I originally mentioned North America because that’s the context I know, but folks from universities the world around have observed the same thing.</li>
  <li>For universities outside the USA, the outsourcing is doubled: they’re not only outsourcing things from the university to outside third parties, they’re outsourcing to companies outside the country.</li>
  <li>The reasons given for this shift vary. In some places, faculty and students are told this is done for security purposes. In others, they are told it’s done for cost-cutting reasons. And in others, they’re told it’s done to protect the university’s brand.</li>
  <li>Timelines also vary. The pandemic sped things up, but such outsourcing has been going on for a while. Some note it began at their institutions as early as the 1990s.</li>
  <li>There are some bright spots: university-hosted Git repositories and local file storage are mentioned.</li>
</ul>

<p>While I didn’t hear that the book on this shift exists, people helpfully pointed out <a href="https://arxiv.org/abs/2104.09462">this article on the “Zoomification” of higher education</a>. Poking around, I also found a <a href="https://www.insidehighered.com/opinion/blogs/learning-innovation/2023/09/01/recoding-america-and-perils-outsourcing-it">book review essay</a> lamenting this process, a report in the <a href="https://www.washingtonpost.com/local/education/colleges-outsourcing-services/2021/01/07/c3f2ac6a-5135-11eb-bda4-615aaefd0555_story.html">Washington Post</a>, and a <a href="https://www.theguardian.com/australia-news/2023/mar/07/australian-university-outsourcing-how-can-i-tell-if-my-online-course-is-being-run-by-a-third-party">Guardian Australia investigation into outsourcing</a>.</p>

<p>The topic is definitely getting attention. Someone outta write a book.</p>

<h2 id="why-i-care-about-this">Why I Care About This</h2>
<p>Readers of this blog know I care about communication infrastructure pretty deeply. Goal 1 of my blog is to <a href="/2020/11/27/introduction.html">document the life of the “FOSS Academic”</a> – my attempt to do most or all of my professorial work using FOSS tools and self-hosting. I use Nextcloud for document sharing, collaboration, and conferencing, Zotero for managing bibliographies, Thunderbird for managing emails and calendars, Libreoffice for writing. I use Syncthing, Wireguard, and Nextcloud on a local network to move data from home to office. Of course, all of this is running on Linux machines (Manjaro KDE, if you’re curious).</p>

<p>For the most part, this has worked, but I am sorry to say it’s increasingly hard. Zoom is a big culprit, of course, but I’ve accepted that. (I use <a href="http://localhost:4000/2021/09/25/Appointments.html">Nextcloud Appointments and Talk pretty often</a>, however).</p>

<p>What I didn’t bargain for was how powerful Microsoft has become. Outlook, Teams, Sharepoint, Office. The assumption among my colleagues is that I use all of these regularly. I get why they think that – it’s what’s provided. But I’m starting to get pressure to put my calendar on Outlook, since people assume that if my Outlook calendar is open, I can meet. Whenever my colleagues want to work on documents, it’s in Office online, not a draft passed back and forth. And all of my department’s governance runs through Teams (a program so awfully designed it wastes time – I can hardly find anything in it).</p>

<p>I’m trying to hold onto my FOSS, self-hosted network as a living experiment – maybe if I can hold the line, chip away at things, convert a colleague or two to the “FOSS Academic Lifestyle Dream” – maybe we can find an alternative to this mess.</p>

<p>But given that university IT outsourcing is a global phenomenon, I’m starting to lose hope.</p>

<h2 id="lost-creativity">Lost Creativity</h2>

<p>Perhaps the biggest reason I’m concerned, however, is not just about my day-to-day work, but because of the loss of skills and experiments such outsourcing causes. This is the point of the <a href="https://www.insidehighered.com/opinion/blogs/learning-innovation/2023/09/01/recoding-america-and-perils-outsourcing-it">book review essay I cited above</a>, in which Joshua Kim uses a book about US government IT outsourcing to lament the loss of IT skills in universities, as well as the reduction of University IT to mere “support services.”</p>

<p>What I would like to see is universities providing infrastructure for students and faculty to do interesting, creative things. I’d like to see this done for <em>all</em> students and faculty, not just sequestered in computer science or engineering departments. I’d like to see folks be able to do everything from making websites to local document collaboration to running their own social media. On this latter point, there are efforts, notably in <a href="https://www.surf.nl/en/mastodon-pilot-for-research-and-education">Holland</a> and at <a href="https://mastodon.mit.edu/about">MIT</a>. But I worry that these are exceptions, not the rule.</p>

<p>More than that, I would like to see universities run their own IT again, seeing it as central to the pedagogical mission, not just another budget line to cut.</p>

<h2 id="did-you-write-this-book">Did you write this book?</h2>

<p>Finally, to repeat my question above: did someone write this book and I just missed it? Hey, let me know: I’m buying!</p>]]></content><author><name>RWG</name></author><category term="Goal 1" /><summary type="html"><![CDATA[My first full-time academic job was at the University of Utah. Utah is, of course, very famous. No, not because of cold fusion or teaching Ted Bundy about the law. It is famous because it was the fourth node on the ARPAnet, the forerunner to the modern internet. The other three nodes were in California; connecting to Utah was a major test of the network’s ability to work across long distances. Although it was a US Defense Department-funded project, the ARPAnet was a playground for academics who took its mission (command-and-control even in spite of a nuclear attack) and turned it into research into networking and collaboration. The pattern continued: academic exploration of computer technologies has produced a bewildering array of experiments, and no doubt students at institutions have benefited greatly from being able to play with local, experimental computer tools while they study. Fast forward to the early 2010s. I’m working at Utah, hired in part to teach a Web design class to Communication majors. Simple enough: each and every person affiliated with Utah had their own domain (something like domain.utah.edu/~username) on a local server, complete with FTP access via their email credentials. I taught students the basics of HTML and CSS. I got to see students who were openly scared of coding make things that appeared on their screens – and on the internet. It was fun! Until it was not. I was at Utah from 2010 to 2020. Over that time, it became harder and harder to get students into their web space. It turns out that Utah was winding down web hosting for everyone, centralizing its web presence and no longer providing web space to anyone. To support our class, the IT folks helpfully carved out some space on a server, specifically for our Comm Intro to the Web Design students, but we knew this was an exception. At the end of my time there, even the machines in the computer lab were outsourced. Instead of fully-functional desktops, students were accessing their servers over a convoluted “thin client” computer lab setup. I had to spend the first 2 weeks just showing them how to find their files – since they were no longer local – and then FTP into a server to move those files over a client-to-cloud-to-FTP setup. This was for students who had no networking or web design experience – it was rough. (And if we needed software – such as basic text editor – good luck getting it when all the software was on a cloud somewhere). I’m sorry to say I spent a great deal of that time in an increasingly adversarial relationship with the IT folks. As this happened, my colleague Sean Lawson and I would vent our frustration by jokingly saying, “Welcome to Node 4!” The irony being that Utah was once 25% of the freakin’ Internet but we could not get easy access to basic Web hosting. It was an ordeal just to get students to the point where they could move a text file they were working on to a server. Fast forward to today. Now, I am happily employed by York University in Toronto. But just the other day, my colleagues met for a faculty meeting, and we discussed recruiting students. Someone suggested we post information about our faculty to our department website and social media. “No,” the chair said. “All of that would have to go through the central administration” – the implication being either it wouldn’t be allowed, or that it would take months to achieve. Someone’s Gotta Write This Book I would propose, were I to have time, to write a book called “How Universities Lost the Internet.” How did we get from many nodes to everything being dumped into California or Redmond, WA? How did we get from a system of experimentation to seeing digital media as a controlled environment to market a brand? How did we get to the point where university core functions were run by for-profit firms? It would be a fascinating book. (Someone else can write it, though; I’m too busy with my current project!)]]></summary></entry><entry><title type="html">Alternative Social Media Preconference at AoIR</title><link href="http://localhost:4000/2023/10/19/AoIR_ASM_preconfernce.html" rel="alternate" type="text/html" title="Alternative Social Media Preconference at AoIR" /><published>2023-10-19T00:00:00-04:00</published><updated>2023-10-19T00:00:00-04:00</updated><id>http://localhost:4000/2023/10/19/AoIR_ASM_preconfernce</id><content type="html" xml:base="http://localhost:4000/2023/10/19/AoIR_ASM_preconfernce.html"><![CDATA[<p>On October 18, at 8.30 am, a group of about 30 Internet Scholars gathered for a Association of Internet Researchers preconference, called “Building an Alternative Social Media Network.”</p>

<p>Organized by Jessa Lingel, Ashwin Nagappi, and myself, the preconference achieved one of its big goals: getting many researchers in a room to talk about alternative social media (ASM). Yay!</p>

<p>The other big goal was igniting a research agenda for ASM. Did we succeed?
<!-- more --></p>

<h2 id="asm-research-futures">ASM Research futures</h2>
<p>I would say: “yes!”</p>

<p>The discussion during our roughly four hours was rich. First of all, Ashwin had the brilliant idea of building an ad-hoc timeline of social media, dating back to the 1970s through today.</p>

<figure>
  <img src="/assets/images/smwall.jpg" alt="A wall of post-it notes that creates a timeline of social media, starting with email in the 1970s through the fediverse today" title="social media timeline" />
  <figcaption>The participants in the preconference remembered various social media, broadly construed, and posted notes about them to the wall.</figcaption>
</figure>

<p>This actually helped us see the variety of ways people were defining “social media” right away. It also showed us that there may have been bursts of activity in two key moments: the early 2010s (quite understandable) and right now.</p>

<h2 id="what-are-asm">What are ASM?</h2>
<p>This segued into a discussion about a key question: what are “alternative social media”? From my corner of the room, I heard two key words:</p>

<ul>
  <li>relational</li>
  <li>emergent</li>
</ul>

<p>That is, ASM are always in relation to something typically considered mainstream. This actually replicates a paper Roel Roscam Abbing and I are working on, where we will conclude with a similar observation. ASM are in relation to a mainstream, a relation that can change over time. RRA and I presented an early <a href="https://nextcloud.robertwgehl.org/index.php/s/qkZBjbznzkjTbkT">version of that paper back in May of this year</a>.</p>

<p>The other key word was “emergent,” in that alternative <em>practices</em> often appear across many locations, including on mainstream corporate social media. These practices can influence both corporate <em>and</em> alternative social media.</p>

<p>However, even with this relative consensus, much as the conception of social media was very broad, so, too the conception of alternative social media. Some of us felt that this would hinder the field, replicating the worst of the alternative media debates of the 1990s-2000s. Others of us felt that the variety of meanings could aid in research.</p>

<h2 id="methods-and-ethics">Methods and Ethics</h2>
<p>We next turned to ASM research methods – which were immediately tied to research ethics.</p>

<p>First of all, since ASM is hard to define, then it struck many of us that ethnographic or participatory methods are called for. We agreed that often we have to listen to communities as they define themselves as “alternative.”</p>

<p>But we also noted that we should be free to reject a community’s self-definition as “alternative” – it could be mere marketing. Or it could be a self-serving gloss on unethical replication of mainstream practices.</p>

<p>Historical methods were also recommended, since tracing alternative practices (such as, for example, federated political practices) could shed light on contemporary social media.</p>

<p>We also discussed approaches like the walk-through method or software studies approaches.</p>

<p>If there was controversy, it was over data-scraping methods. Readers of this blog know I am adverse to them on the fediverse (and I am working on a paper on this topic). However, participants argued that scraping may be warranted in situations where we study the alt-right.</p>

<p>Ethics was, as it should be, a central consideration. The participants tended to agree with the basic idea of consent – a position I <a href="/2023/06/25/ASMupdate-Warwick.html">wholly endorse for the study of the fediverse</a>.</p>

<p>The sticky bit, again, was in cases where researchers felt that consent would be hard to get, or interfere with the study: again, this tended to focus on studying right-wing alternative social media.</p>

<p>For me (and many of the folks in the room, I believe), there’s a major upshot to ethical engagement with many ASM groups: we researchers can make a difference! We can do work that resonates with ASM communities: we can ask them what they need and how we could help provide it through research. I really don’t think Facebook or Twitter cares a bit about critical social media research… but people on the fediverse, for example, might. If we do this right, we can actually help grow a more ethical social media.</p>

<p>I’m down for that!</p>

<h2 id="future-steps">Future steps</h2>
<p>We are now building an email listserv for researchers interested in the field of ASM, as well as a Zotero library. I particularly hope that collecting a bibliography might shed light on the field.</p>

<p>We are also talking about meeting again, either virtually or in person. Watch this space for more!</p>]]></content><author><name>RWG</name></author><category term="alternative social media" /><category term="Association of Internet Researchers" /><category term="Goal 2" /><summary type="html"><![CDATA[On October 18, at 8.30 am, a group of about 30 Internet Scholars gathered for a Association of Internet Researchers preconference, called “Building an Alternative Social Media Network.” Organized by Jessa Lingel, Ashwin Nagappi, and myself, the preconference achieved one of its big goals: getting many researchers in a room to talk about alternative social media (ASM). Yay! The other big goal was igniting a research agenda for ASM. Did we succeed?]]></summary></entry><entry><title type="html">ActivityPub, the Non-Standard Standard</title><link href="http://localhost:4000/2023/10/15/APnonStandard.html" rel="alternate" type="text/html" title="ActivityPub, the Non-Standard Standard" /><published>2023-10-15T00:00:00-04:00</published><updated>2023-10-15T00:00:00-04:00</updated><id>http://localhost:4000/2023/10/15/APnonStandard</id><content type="html" xml:base="http://localhost:4000/2023/10/15/APnonStandard.html"><![CDATA[<p>In a couple days, I head to Philadelphia for the 2023 version of the Association of Internet Researchers conference. It’s my favorite conference. And to give AOIR even more credit, they were one of the first professional academic organizations to set up <a href="https://aoir.social">their own Mastodon instance</a> (I participate in that project by helping run the instance).</p>

<p>While there, I will present a paper about the creation of <a href="https://www.w3.org/TR/activitypub/">ActivityPub</a>, the protocol that allows the contemporary fediverse to run.</p>

<p>Titled “The Non-Standard Standard: A Critical Genealogy of ActivityPub,” I will argue that ActivityPub is a very unusual standard. While it was created by a W3C working group, <a href="https://www.w3.org/wiki/Socialwg">the Social Web Working Group</a> during <a href="https://www.w3.org/2023/Process-20230612/">a W3C standard process</a>, there were many non-standard aspects to its creation.</p>

<p>In this post, I’ll sum up my findings, arguing that there are four ways in which ActivityPub is a non-standard standard. This work is informed by reading the Social Web Working Group (SocialWG) meeting minutes, interviews with SocialWG members, and a study of historical documents.</p>

<p>Comments are very welcome, since this is going to be a chapter in my forthcoming book about the fediverse, <a href="/2023/08/17/OxfordUP.html"><em>Move Slowly and Build Bridges</em></a>.</p>

<!-- more -->

<h2 id="four-non-standard-aspects-of-the-activitypub-standard">Four Non-Standard Aspects of the ActivityPub standard</h2>
<h3 id="1-corporate-social-media-was-not-involved">1) Corporate social media was not involved</h3>
<p>Corporate social media wasn’t involved in the production of ActivityPub. At best, corporations like Facebook or Twitter (as they were known at the time) treated the SocialWG with benign neglect. At worst, they saw the group as utterly irrelevant to the future of social media.</p>

<p>It wasn’t as if the SocialWG didn’t try to get corporate social media involved: they repeatedly reached out to Facebook, Twitter, Sina Weibo, and other major social media corporations. But none of these companies got involved.</p>

<p>This is very unusual in the world of internet standards. Companies such as IBM, Microsoft, Apple, Google, Meta, Oracle, or Samsung pay membership fees and regularly send employees to standards-setting bodies, such as the Internet Engineering Task Force and the World Wide Web Consortium, in order to shape the standards that govern their industries. In fact, as much as corporations like Apple, Microsoft, and Google appear to be competing with one another, in reality they often cooperate when building standards, because the general rule is that standardized technologies are good for business.</p>

<p>But when it came to the SocialWG, as ActivityPub co-author Amy Guy told me, “None of the big players… no one took us seriously. No one saw [the SocialWG] as a threat. No one expected it to go anywhere…. The feeling was, it was small beans, and it wasn’t worth their time.”</p>

<h3 id="2-the-social-web-working-group-didnt-make-a-standard--they-made-seven">2) The Social Web Working Group Didn’t Make a Standard – They Made <em>Seven</em></h3>
<p>Instead of settling on one approach to standardizing social media – in other words, a single, standard approach – the group made <a href="https://www.w3.org/groups/wg/social/publications/">seven standards</a>. For a typical W3C working group, that is decidedly non-standard behavior – most groups make one or two.</p>

<p>Based on interviews, it’s clear this happened because of a lack of corporate involvement. Say what we will about corporate social media, they at least have a clear goal in mind: more users. More people’s lives to datamine, more eyeballs on behavioral ads.</p>

<p>In contrast, the SocialWG members took a predominantly academic or theoretical approach, which initially resulted in multiple factions each championing their own approaches. The group easily could have produced zero standards.</p>

<p>But in a compromise, the SocialWG decided to produce many standards. In a sense, as SocialWG member Bengo told me, the group succeeded <em>too much</em> – it made many standards, instead of just one or two.</p>

<p>All this said, while lack of corporate involvement might have unmoored the group somewhat, the interviewees I spoke to said they were grateful to make standards that did not simply support the needs of corporate social media.</p>

<h3 id="3-activitypub-almost-didnt-happen">3) ActivityPub Almost Didn’t Happen</h3>
<p>This is the biggee. ActivityPub – the most successful product of the SocialWG by far – almost didn’t get done.</p>

<p>One big reason was that a federation protocol was considered to be optional by the <a href="https://www.w3.org/2013/socialweb/social-wg-charter.html">SocialWG’s charter</a>.</p>

<p>But an even bigger hurdle came in the face of resistance to ActivityPub from within the SocialWG itself. As an example of the pushback, consider this Mean Girls meme:</p>

<figure>
  <img src="/assets/images/fetchfederation.jpg" alt="Mean Girls &quot;Stop Trying to Make Federation Happen&quot; meme" title="Stop Trying to Make Federation Happen" />
  <figcaption>A variation on the Mean Girls "stop trying to make fetch happen," adapted to refer to the federation protocol</figcaption>
</figure>

<p>Fortunately for us, ActivityPub advocates such as eventual co-author <a href="https://dustycloud.org/">Christine Lemmer-Webber</a> weren’t taking no for an answer. Lemmer-Webber pushed back hard against the resistance to ActivityPub.</p>

<p>However, even with Lemmer-Webber championing it, time was running out: the SocialWG charter set the end of the group to be mid-2017.</p>

<p>It took Mastodon to save ActivityPub. <a href="https://hackernoon.com/mastodon-and-the-w3c-f75f376f422">Mastodon implemented a draft version of ActivityPub</a>, and because this was a big deal, the W3C gave the SocialWG <em>two</em> deadline extensions, now known as the “Mastodon Extension.”</p>

<p>Mastodon and ActivityPub connected because of their respective developers’ desire for safety for queer and trans people. Just as “the fediverse has historically been extremely queer,” <a href="https://fossandcrafts.org/episodes/053-fediverse-reflections-while-the-bird-burns.html">Christine Lemmer-Webber explains that ActivityPub was, as well</a>. Lemmer-Webber says ActivityPub “was largely developed by queer people – myself included – and including also implementation developers.” Four of the five ActivityPub authors self-identified as queer.</p>

<p>As for Mastodon, Lemmer-Webber recalls that a large number of its “key contributors, kind of set the tone by pushing for certain features and pushing for kind of certain cultural norms that were to support queer communities that did not feel well-supported by Twitter.”</p>

<p>So, ActivityPub solved many problems for Mastodon – it functioned as a privacy-respecting upgrade over <a href="https://en.wikipedia.org/wiki/OStatus">OStatus</a> (the original protocol used by Mastodon), a means to break away from harassment coming from some <a href="https://medium.com/@Trevatos/gnu-social-pleroma-and-the-mastodon-culture-conflict-3b10872937c2">GNU social servers</a>, and a way to further differentiate itself from Twitter. And Mastodon helped ActivityPub by giving its authors a big implementation – gold in the world of standards.</p>

<h3 id="4-mastodon-prompted-us-to-ignore-12-of-activitypub">4) Mastodon Prompted Us to Ignore 1/2 of ActivityPub</h3>
<p>However, while Mastodon saved ActivityPub from oblivion, it has also effectively erased half of the ActivityPub standard from the internet. This is because the <a href="https://docs.joinmastodon.org/api/">Mastodon API</a> is dominant across the fediverse, with non-Mastodon projects adopting it. This is in spite of the fact that the ActivityPub protocol includes an API for clients, which would allow end clients to connect to any fediverse server regardless of what software the server is running.</p>

<p>This client-to-server portion of ActivityPub is cited by SocialWG members as their favorite part of the standard. But it is effectively ignored. So while ActivityPub’s creators are grateful to Mastodon for saving their work, Mastodon is also a cause for lament on the part of the ActivityPub authors.</p>

<h2 id="implications-for-the-future">Implications for the Future?</h2>

<p>Overall, I found the story of ActivityPub, the non-standard standard, to be fascinating. Obviously, it’s also important to the history of Mastodon. As Evan Prodromou told me in an interview, the meeting of Mastodon and ActivityPub at just the right moment in both their development “has changed history. It could be a very different story now. A different story for Mastodon and a different story for the social web.”</p>

<p>I also wonder how this story will affect the future, as well. People are currently reviving the SocialWG, with debates happening right now about what its scope should be. Given the history I’ve observed, I would argue that concentrating on the SocialWG’s most successful product, ActivityPub, may be the wisest move.</p>]]></content><author><name>RWG</name></author><category term="ActivityPub" /><category term="Goal 2" /><category term="Move Slowly and Build Bridges" /><summary type="html"><![CDATA[In a couple days, I head to Philadelphia for the 2023 version of the Association of Internet Researchers conference. It’s my favorite conference. And to give AOIR even more credit, they were one of the first professional academic organizations to set up their own Mastodon instance (I participate in that project by helping run the instance). While there, I will present a paper about the creation of ActivityPub, the protocol that allows the contemporary fediverse to run. Titled “The Non-Standard Standard: A Critical Genealogy of ActivityPub,” I will argue that ActivityPub is a very unusual standard. While it was created by a W3C working group, the Social Web Working Group during a W3C standard process, there were many non-standard aspects to its creation. In this post, I’ll sum up my findings, arguing that there are four ways in which ActivityPub is a non-standard standard. This work is informed by reading the Social Web Working Group (SocialWG) meeting minutes, interviews with SocialWG members, and a study of historical documents. Comments are very welcome, since this is going to be a chapter in my forthcoming book about the fediverse, Move Slowly and Build Bridges.]]></summary></entry><entry><title type="html">A defense of the humble, importable blocklist</title><link href="http://localhost:4000/2023/09/20/blocklists.html" rel="alternate" type="text/html" title="A defense of the humble, importable blocklist" /><published>2023-09-20T00:00:00-04:00</published><updated>2023-09-20T00:00:00-04:00</updated><id>http://localhost:4000/2023/09/20/blocklists</id><content type="html" xml:base="http://localhost:4000/2023/09/20/blocklists.html"><![CDATA[<p>So I tried to take part in Fediforum today, but I wasn’t really able to participate. My initial idea was to get into a debate with my friend <a href="https://test.roelof.info/">Roel Roscam Abbing</a>, who is an incredibly deep thinker and is writing what will no doubt be a foundational dissertation about the fediverse. We were hoping to prompt a discussion about importable, instance blocklists on the fediverse.</p>

<p>He and I disagree their utility. He thinks they’re bad; I think they’re good. I’ll let him post his reasons why, but here I wanted to share my defense of them. What follows is a longer version of what I planned on presenting at Fediforum.</p>

<!-- more -->

<p>Often, when people discuss ways to improve the fediverse, they talk about technical solutions – extensions to ActivityPub, say, or new layers on the network. Instead, my take is informed by my research for <a href="/2023/08/17/OxfordUP.html">my forthcoming book</a>, where I explore the history, politics, and cultural practices of the fediverse. To defend blocklists, I draw on this history, politics, and culture.</p>

<p>One of the most powerful things that has emerged on the fediverse is the culture of Codes of Conduct. The fediverse would be a very different –- and worse –- place without this practice.</p>

<p>The practice of using codes of conduct was not a technical achievement. It has little to do with ActivityPub. Instead, it came as part of the zeitgeist –- COCs were being <a href="https://modelviewculture.com/pieces/codes-of-conduct-when-being-excellent-is-not-enough">advocated for in tech circles in the mid-2010s</a>, and of course Mastodon was developed right at the same time. Mastodon.social and others adopted COCs, and the pattern was set.</p>

<p>Today, research shows that there are many overlaps across fediverse codes of conduct, such that we see what <a href="https://en.wikipedia.org/wiki/Iris_Marion_Young">ethical theorists</a> might call a thin set of shared global values. A colleague and I argue elsewhere that this practice gives rise to the <a href="https://www.tandfonline.com/doi/full/10.1080/1369118X.2022.2147400">“covenantal fediverse,”</a> where like-minded instances band together.</p>

<p>Another social innovation is the emergence of the instance as the fundamental unit of the fediverse. I know that there was a desire by the <a href="https://www.w3.org/2013/socialweb/social-wg-charter.html">authors of ActivityPub to have a client-to-server structure</a>, but we ended up with instances as the key site of organization. This is a happy accident. Instances admins can gain knowledge about how the network works, where the good and bad actors are, and they can protect members –- especially new members who are just joining the network. For better or worse –-and I think it’s for better –- we think at the community/instance level, with admins as leaders.</p>

<p>This brings me to blocklists. With the <a href="https://github.com/mastodon/mastodon/releases/tag/v4.1.0">implementation of blocklist importing in Mastodon</a>, we’re seeing a logical next step –- not just the sharing of codes of conduct, but cross-instance, inter-admin sharing of knowledge about what Ro aptly calls <a href="https://thebad.space/">“the bad space”</a> of the fediverse. This is a recognition –- and blocking –- of the swath of the internet that fails to meet the thin set of global ethical values. Contemporary blocklists are a codification of early social practices, like #fediblock and backchanneling between covenantally-linked instances.</p>

<p>As I’ve <a href="https://nextcloud.robertwgehl.org/index.php/s/G34Y5X2PoNBq5Xp">noted elsewhere</a>, I’ve benefited from this history. When I set up AOIR.social in March, I was aided by imported blocklists. There is a great deal of knowledge on the fediverse about the patterns of “free speech absolutism” (read: racist, misogynist, transmisic, or CSAM-sharing). Free speech absolutism has a long history in free software social media. But because people have recognized the freezepeach pattern – indeed, because they’ve suffered from it – they have codifed their knowledge in blocklist form. Installing a blocklist on day one allowed AoIR.social to benefit from this painfully-gained knowledge.</p>

<p>There are counterarguments, of course. The danger of a blocklist is that it is tied to personalities –- many people cite the <a href="https://medium.com/@obvious_humor/dont-use-randi-harper-s-blocklist-use-naziblocker-instead-db16cd666d49">Randi Harper case</a>. Others suggest that blocklists are too tied to centralized, corporate social media. But I think we run the risk of the genetic fallacy by assuming previous, harmful Twitter activities will necessarily be replicated on the fedi.</p>

<p>Countering the danger of the blocklist run by a single person, we’re seeing nascent governance structures around blocklists, including <a href="https://nivenly.org/docs/papers/fsep/">Ro’s The Bad Space collaboration with Nivenly</a>.</p>

<p>And this brings me to my main point. Much the same as we’ve had an emergent set of ethical principles arise through the cultural practice of COCs, organized at the instance level, shared instance blocklists –- with governance structures that cross instances –- could result in another cultural innovation: affirmative, cross-instance governance. The blocklist becomes a vehicle for such collaboration.</p>

<p>It won’t be easy, by any means. In fact, it is really hard (just ask the people helping to build the lists). But so was developing codes of conduct. And so too is running an instance. It’s all social practice. It’s all hard. Building a new way of being social is hard.</p>

<p>But we’re gaining skills, day by day.</p>]]></content><author><name>RWG</name></author><category term="moderation" /><category term="goal 2" /><summary type="html"><![CDATA[So I tried to take part in Fediforum today, but I wasn’t really able to participate. My initial idea was to get into a debate with my friend Roel Roscam Abbing, who is an incredibly deep thinker and is writing what will no doubt be a foundational dissertation about the fediverse. We were hoping to prompt a discussion about importable, instance blocklists on the fediverse. He and I disagree their utility. He thinks they’re bad; I think they’re good. I’ll let him post his reasons why, but here I wanted to share my defense of them. What follows is a longer version of what I planned on presenting at Fediforum.]]></summary></entry></feed>