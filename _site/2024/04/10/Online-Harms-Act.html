<!doctype html>
<html lang="en">
	<head>
	<meta charset="utf-8">
	<title>FOSS ACADEMIC | Reading the Online Harms Act with my Fediverse Admin Hat On</title>
    <link rel="stylesheet" href="/assets/css/reset.css">
	<link rel="stylesheet" media="screen and (min-width: 1080px)" href="/assets/css/desktop.css" />
    <link rel="stylesheet" media="screen and (max-width: 1079px)" href="/assets/css/mobile.css" />

    <link rel="shortcut icon" href="/favicon.ico" />
	<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="FOSS Academic" />
	<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Reading the Online Harms Act with my Fediverse Admin Hat On | FOSS Academic</title>
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="Reading the Online Harms Act with my Fediverse Admin Hat On" />
<meta name="author" content="RWG" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The Online Harms Act is currently the talk of Canada. As the government’s website describes it, The internet is an exceptional tool for people of all ages to learn, play and connect with family, friends and those with similar interests. However, just like the outside world, the digital world can pose significant dangers. Social media can be used to sexually exploit children, promote self-harm to children, incite violence, put people’s safety at risk and foment hate. Online harms have real-world impacts with tragic, even fatal, consequences. The Government of Canada has introduced legislation to hold social media platforms accountable for addressing harmful content on their platforms and for creating a safer online space that protects all people in Canada, especially kids. As something that addresses speech on the internet – and includes some strong penalties for spreading hate speech – the Act has led to massive debates. I won’t summarize them here, but you can read thoughtful critiques from Professor Michael Geist and you can listen to a discussion on Canadaland’s Backbench to get a sense of things. My interest here is not to delve into the controversies, but instead read the Act while wearing my Mastodon admin hat. I am one of the two admins of AoIR.social, a Mastodon instance for members of the Association of Internet Researchers. AoIR.social gives our members access to the fediverse – the global network of thousands of social media servers, with millions of users engaged in social media activities. An initial question: does the Act apply to the tens of thousands of fediverse instances with their millions of users? Does it thus apply to AoIR.social? Considering that the Act defines “social media service” as “a website or application that is accessible in Canada, the primary purpose of which is to facilitate interprovincial or international online communication among users of the website or application by enabling them to access and share content” (page 5), then the answer is yes. AoIR.social operates internationally, including in Canada. So do many of the other tens of thousands of fediverse servers. Since I’m one of the two admins of AoIR.social, am I affected? I believe so: I would be an “operator,” “a person that, through any means, operates a regulated service.” It could also be that the AoIR organization itself would be the operator, since in this Act “person” also applies to corporations. The Act would create a Digital Safety Commission, an agency that would govern social media services. The Act notes this Commission should consider things like the size of the service and the operator’s financial and technical abilities. This is good – many fediverse instances are small and are run by individuals or a handful of folks. They also often run on very small budgets as not-for-profit organizations. Regardless, however, I believe small fediverse servers would be affected (unless they find a way to not be available to Canadians). So: will the Act radically affect fediverse instances, such as AoIR.social? The Act specifically says our service should not harm freedom of expression, and reading it leads me to believe that AoIR.social won’t be affected in that manner. While we welcome debate and discussion, we’re not in the business of platforming the sorts of harmful content the Act discusses. But, the implementation of the Act could prove to be very burdensome to the administration of fediverse instances, such as AoIR.social. Much is going to hinge on how the Act understands the fediverse." />
<meta property="og:description" content="The Online Harms Act is currently the talk of Canada. As the government’s website describes it, The internet is an exceptional tool for people of all ages to learn, play and connect with family, friends and those with similar interests. However, just like the outside world, the digital world can pose significant dangers. Social media can be used to sexually exploit children, promote self-harm to children, incite violence, put people’s safety at risk and foment hate. Online harms have real-world impacts with tragic, even fatal, consequences. The Government of Canada has introduced legislation to hold social media platforms accountable for addressing harmful content on their platforms and for creating a safer online space that protects all people in Canada, especially kids. As something that addresses speech on the internet – and includes some strong penalties for spreading hate speech – the Act has led to massive debates. I won’t summarize them here, but you can read thoughtful critiques from Professor Michael Geist and you can listen to a discussion on Canadaland’s Backbench to get a sense of things. My interest here is not to delve into the controversies, but instead read the Act while wearing my Mastodon admin hat. I am one of the two admins of AoIR.social, a Mastodon instance for members of the Association of Internet Researchers. AoIR.social gives our members access to the fediverse – the global network of thousands of social media servers, with millions of users engaged in social media activities. An initial question: does the Act apply to the tens of thousands of fediverse instances with their millions of users? Does it thus apply to AoIR.social? Considering that the Act defines “social media service” as “a website or application that is accessible in Canada, the primary purpose of which is to facilitate interprovincial or international online communication among users of the website or application by enabling them to access and share content” (page 5), then the answer is yes. AoIR.social operates internationally, including in Canada. So do many of the other tens of thousands of fediverse servers. Since I’m one of the two admins of AoIR.social, am I affected? I believe so: I would be an “operator,” “a person that, through any means, operates a regulated service.” It could also be that the AoIR organization itself would be the operator, since in this Act “person” also applies to corporations. The Act would create a Digital Safety Commission, an agency that would govern social media services. The Act notes this Commission should consider things like the size of the service and the operator’s financial and technical abilities. This is good – many fediverse instances are small and are run by individuals or a handful of folks. They also often run on very small budgets as not-for-profit organizations. Regardless, however, I believe small fediverse servers would be affected (unless they find a way to not be available to Canadians). So: will the Act radically affect fediverse instances, such as AoIR.social? The Act specifically says our service should not harm freedom of expression, and reading it leads me to believe that AoIR.social won’t be affected in that manner. While we welcome debate and discussion, we’re not in the business of platforming the sorts of harmful content the Act discusses. But, the implementation of the Act could prove to be very burdensome to the administration of fediverse instances, such as AoIR.social. Much is going to hinge on how the Act understands the fediverse." />
<link rel="canonical" href="http://localhost:4000/2024/04/10/Online-Harms-Act.html" />
<meta property="og:url" content="http://localhost:4000/2024/04/10/Online-Harms-Act.html" />
<meta property="og:site_name" content="FOSS Academic" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-04-10T00:00:00-04:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Reading the Online Harms Act with my Fediverse Admin Hat On" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"RWG"},"dateModified":"2024-04-10T00:00:00-04:00","datePublished":"2024-04-10T00:00:00-04:00","description":"The Online Harms Act is currently the talk of Canada. As the government’s website describes it, The internet is an exceptional tool for people of all ages to learn, play and connect with family, friends and those with similar interests. However, just like the outside world, the digital world can pose significant dangers. Social media can be used to sexually exploit children, promote self-harm to children, incite violence, put people’s safety at risk and foment hate. Online harms have real-world impacts with tragic, even fatal, consequences. The Government of Canada has introduced legislation to hold social media platforms accountable for addressing harmful content on their platforms and for creating a safer online space that protects all people in Canada, especially kids. As something that addresses speech on the internet – and includes some strong penalties for spreading hate speech – the Act has led to massive debates. I won’t summarize them here, but you can read thoughtful critiques from Professor Michael Geist and you can listen to a discussion on Canadaland’s Backbench to get a sense of things. My interest here is not to delve into the controversies, but instead read the Act while wearing my Mastodon admin hat. I am one of the two admins of AoIR.social, a Mastodon instance for members of the Association of Internet Researchers. AoIR.social gives our members access to the fediverse – the global network of thousands of social media servers, with millions of users engaged in social media activities. An initial question: does the Act apply to the tens of thousands of fediverse instances with their millions of users? Does it thus apply to AoIR.social? Considering that the Act defines “social media service” as “a website or application that is accessible in Canada, the primary purpose of which is to facilitate interprovincial or international online communication among users of the website or application by enabling them to access and share content” (page 5), then the answer is yes. AoIR.social operates internationally, including in Canada. So do many of the other tens of thousands of fediverse servers. Since I’m one of the two admins of AoIR.social, am I affected? I believe so: I would be an “operator,” “a person that, through any means, operates a regulated service.” It could also be that the AoIR organization itself would be the operator, since in this Act “person” also applies to corporations. The Act would create a Digital Safety Commission, an agency that would govern social media services. The Act notes this Commission should consider things like the size of the service and the operator’s financial and technical abilities. This is good – many fediverse instances are small and are run by individuals or a handful of folks. They also often run on very small budgets as not-for-profit organizations. Regardless, however, I believe small fediverse servers would be affected (unless they find a way to not be available to Canadians). So: will the Act radically affect fediverse instances, such as AoIR.social? The Act specifically says our service should not harm freedom of expression, and reading it leads me to believe that AoIR.social won’t be affected in that manner. While we welcome debate and discussion, we’re not in the business of platforming the sorts of harmful content the Act discusses. But, the implementation of the Act could prove to be very burdensome to the administration of fediverse instances, such as AoIR.social. Much is going to hinge on how the Act understands the fediverse.","headline":"Reading the Online Harms Act with my Fediverse Admin Hat On","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2024/04/10/Online-Harms-Act.html"},"url":"http://localhost:4000/2024/04/10/Online-Harms-Act.html"}</script>
<!-- End Jekyll SEO tag -->

</head>

<body>
    <div id="wrapper">
    <header>
    <img src="/assets/images/tuxpen.png" alt="Tux the Penguin reading books">
    <h1><a href="/index.html">FOSS Academic</a></h1>
</header>

    <nav>
    <ul>
  
        <li>
	        <a href="/" >
		        Home
	        </a>
        </li>
  
        <li>
	        <a href="/about.html" >
		        About
	        </a>
        </li>
  
        <li>
	        <a href="/bib.html" >
		        Bibliography
	        </a>
        </li>
  
        <li>
	        <a href="/feed.xml" >
		        Feed
	        </a>
        </li>
  
    </ul>
</nav>
	
    <main>
    <div>
    <h1 class="postHeader">Reading the Online Harms Act with my Fediverse Admin Hat On</h1>

    <p class="byline">
        10 Apr 2024
        
        
        - <a href="/authors/RWG.html">Robert W. Gehl</a>
        
    </p>

    <p>The <a href="https://www.canada.ca/en/canadian-heritage/services/online-harms.html">Online Harms Act</a> is currently the talk of Canada. As the government’s website describes it,</p>
<blockquote>
  <p>The internet is an exceptional tool for people of all ages to learn, play and connect with family, friends and those with similar interests. However, just like the outside world, the digital world can pose significant dangers. Social media can be used to sexually exploit children, promote self-harm to children, incite violence, put people’s safety at risk and foment hate. Online harms have real-world impacts with tragic, even fatal, consequences.</p>
</blockquote>

<blockquote>
  <p>The Government of Canada has introduced legislation to hold social media platforms accountable for addressing harmful content on their platforms and for creating a safer online space that protects all people in Canada, especially kids.</p>
</blockquote>

<p>As something that addresses speech on the internet – and includes some strong penalties for spreading hate speech – the Act has led to massive debates. I won’t summarize them here, but you can read thoughtful critiques from <a href="https://www.michaelgeist.ca/tag/online-harms-act/">Professor Michael Geist</a> and you can listen to a discussion on <a href="https://www.canadaland.com/podcast/85-the-hate-u-post/">Canadaland’s Backbench</a> to get a sense of things.</p>

<p>My interest here is not to delve into the controversies, but instead read the Act while wearing my Mastodon admin hat. I am one of the two admins of AoIR.social, a <a href="https://en.wikipedia.org/wiki/Mastodon_(social_network)">Mastodon</a> instance for members of the <a href="https://aoir.org/">Association of Internet Researchers</a>. AoIR.social gives our members access to <a href="https://en.wikipedia.org/wiki/Fediverse">the fediverse</a> – the global network of thousands of social media servers, with millions of users engaged in social media activities.</p>

<p>An initial question: does the Act apply to the tens of thousands of fediverse instances with their millions of users? Does it thus apply to AoIR.social? Considering that the Act defines “social media service” as “a website or application that is accessible in Canada, the primary purpose of which is to facilitate interprovincial or international online communication among users of the website or application by enabling them to access and share content” (page 5), then the answer is yes. AoIR.social operates internationally, including in Canada. So do many of the other tens of thousands of fediverse servers.</p>

<p>Since I’m one of the two admins of AoIR.social, am I affected? I believe so: I would be an “operator,” “a person that, through any means, operates a regulated service.” It could also be that the AoIR organization itself would be the operator, since in this Act “person” also applies to corporations.</p>

<p>The Act would create a Digital Safety Commission, an agency that would govern social media services. The Act notes this Commission should consider things like the size of the service and the operator’s financial and technical abilities. This is good – many fediverse instances are small and are run by individuals or a handful of folks. They also often run on very small budgets as not-for-profit organizations. Regardless, however, I believe small fediverse servers would be affected (unless they find a way to not be available to Canadians).</p>

<p>So: will the Act radically affect fediverse instances, such as AoIR.social? The Act specifically says our service should not harm freedom of expression, and reading it leads me to believe that AoIR.social won’t be affected in that manner. While we welcome debate and discussion, we’re not in the business of platforming the sorts of harmful content the Act discusses.</p>

<p>But, the implementation of the Act could prove to be very burdensome to the administration of fediverse instances, such as AoIR.social. Much is going to hinge on how the Act understands the fediverse.</p>

<!-- more -->

<h2 id="duties-of-operators-of-regulated-services">Duties of Operators of Regulated Services</h2>
<p>The Act is meant to regulate social media, and it lays out various duties social media service operators must follow.</p>

<p>The first is the duty to act responsibly: “The operator of a regulated service must implement measures that are adequate to mitigate the risk that users of the service will be exposed to harmful content on the service.”  Another is a duty to protect children, and related to both, there’s also the duty to make harmful content inaccessible to Canadians.</p>

<p>As a fediverse admin, I have two key questions about these duties. First, what is “harmful content”? This is defined on page 4 in the definitions section:</p>
<ul>
  <li>“(a) intimate content communicated without consent;</li>
  <li>(b) content that sexually victimizes a child or revictimizes a survivor;</li>
  <li>(c) content that induces a child to harm themselves;</li>
  <li>(d) content used to bully a child;</li>
  <li>(e) content that foments hatred;</li>
  <li>(f) content that incites violence; and</li>
  <li>(g) content that incites violent extremism or terrorism.”</li>
</ul>

<p>So, things like revenge “porn”, child sexual abuse material, hate speech, and terrorist speech are prohibited. There are definitions offered for each of these, so I won’t define them here. Frankly, I have no problem blocking these things.</p>

<p>The other question I have is about the responsibility to “mitigate the risk that users of the service will be exposed to harmful content….” It seems to me that this is not just about removing content that’s posted. It’s about reducing the likelihood AoIR.social members will see such harmful content.</p>

<p><em>This</em> is where I have a lot of concerns. Some things seem easy to do, but there are other things that I’m not sure about.</p>

<p>Put simply, the TL;DR summary of the issue is: does the Act consider something like a fediverse server an independent social media site? Or would the Act see the fediverse as a singular network, with traffic being load-balanced across multiple servers?</p>

<p>Let’s get into the details.</p>

<h2 id="whats-easily-done">What’s Easily Done</h2>
<p>The Act calls for social media to publish “Guidelines.” These “must be accessible and easy to use and must include (a) a standard of conduct that applies to users with respect to harmful content; and (b) a description of the measures that the operator implements with respect to harmful content on the service.”</p>

<p>This is pretty easy to comply with, because like many other Mastodon instances, <a href="https://aoir.social/about">AoIR.social has a code of conduct</a>. I believe our code is “accessible and easy to use,” and it explicitly establishes a standard of conduct, which includes prohibitions on the sorts of content the Act describes.</p>

<p>The Act also calls for social media to provide users with “tools to block users” – done and done, because this was baked into Mastodon from its early days.</p>

<p>And the duty to protect children is quite easy for AoIR.social since our membership is limited to dues-paying members of the Association of Internet Researchers, and I don’t think that population includes anyone under 20, let alone minors.</p>

<h2 id="whats-less-clear">What’s Less Clear</h2>
<h3 id="tools-and-processes-to-flag-harmful-content">Tools and processes to flag harmful content</h3>
<p>One feature called for is to “enable a user to easily flag to the operator content that is accessible on the service as being a particular type of harmful content.” That’s baked into Mastodon, so easy enough.</p>

<p>But some of it is not as easy to do, such as “notify a user who flagged content as being a particular type of harmful content of the operator’s receipt of the flag as well as of any measures taken by the operator with respect to the content or of the fact that no measures were taken.” Mastodon does not automatically do this, so it would have to be something the admin/mod does on their own. On AoIR.social, if a user flags something and we block it, we don’t really bother to go back to the original flagger and say we did so. We just do it and move on. I suppose we can do the extra step, but it will add work.</p>

<p>But some of it seems misguided to me: “notify a user who communicated content that was flagged as being a particular type of harmful content of the fact that the content was flagged as well as of any measures taken by the operator with respect to the content or of the fact that no measures were taken.” Mastodon <em>definitely</em> does not do this. I believe this is by design, because notifying people that they have had their content removed can invite more harassment. The approach on Mastodon is to block and not really let the blocked person know. I believe this is for safety purposes –- if we block someone’s content and tell them, they might harass us.</p>

<p>That’s not likely to happen if it’s an AoIR.social member. But the big issue is: <strong>does the Act require me to do these actions with people who are not on my server?</strong> If this is all meant to take place <em>within</em> my server, it’s probably not a problem. Most such in-server moderation is going to involve a discussion with the “user who communicated content that was flagged.” In the case of a user who posts something abhorrent, they’re going to be booted. In the case of someone who posts something borderline, we’re going to chat about it. It’s not going to be a formal process, but more personal.</p>

<p>However, if this is meant to govern my interactions with a user on a server <em>outside</em> my instance, I don’t think this is wise, and it could backfire. If, for example, some trolls are harassing people on AoIR.social, I might communicate with them to tell them to stop, but most likely I’m just going to block them (and hence remove their posts) and not explain myself. Explaining myself would probably lead to more harassment, both for the original victim and likely for me or other AoIR.social moderators.</p>

<p>How the Act handles this is going to matter. If the Act looks at the fediverse and sees a bunch of independent servers which can connect to one another and can sever those connections but have no power over each other, that’s fine. (This is how I think of the fediverse). I can moderate my own server easily enough, and even with the Act in force, the moderation burden might not change all that much (depending on how it is implemented – see below).</p>

<p>If, however, the Act sees a large social media network that distributes the load across multiple resources, then it’s going to raise a great deal of problems for admins like myself. It’s going to create big burdens – and could even lead to more harmful speech.</p>

<h3 id="digital-safety-plan">Digital Safety Plan</h3>
<p>The issue with how the Act would see the fediverse is really intense when it comes to the Digital Safety Plan section. “The operator of a regulated service must submit a digital safety plan to the [Digital Safety] Commission in respect of each regulated service that it operates,” the Act states.</p>

<p>The details are going to matter a great deal here. As someone attempting to immigrate to Canada, I have some familiarity with Canadian bureaucracy. Much of it is quite straightforward, but some of it is onerous and confusing. If AoIR.social will have to supply such a plan, what will it entail? How will it be submitted? Will it be like getting my social insurance number (which was super easy) or like going through the work permit process (which was pretty labor-intensive)?</p>

<p>Looking at the details, I have concerns. For example is point G of the Digital Safety Plan, which would ask me to report</p>
<blockquote>
  <p>information respecting (i) the number of times that content that was accessible on the service was flagged to the operator by users of the service as being harmful content, including the number of flags relating to each type of harmful content, (ii) the manner in which the operator triaged and assessed the flags, (iii) measures taken by the operator with respect to content that was flagged as being harmful content, and (iv) the time within which the operator took measures with respect to content that was flagged as being harmful content.</p>
</blockquote>

<p>This would be easy enough – again, <em>if it’s limited to my server.</em> AoIR.social members are a collegial, professional lot. I simply don’t expect any of them to post harmful content, and thus I don’t expect to have to often report that they flagged content on our own server. And maybe this would be the case. I can indeed interpret the Act’s “users of the service” to be limited to AoIR.social members.</p>

<p>But this does raise a separate potential problem. If the Act sees the fediverse as a bunch of independent servers, what happens when someone outside my server flags something on my server? For the sake of argument, let’s say AoIR.social is actually a bad actor on the fediverse, and our members share harmful content regularly, and that we don’t report each other (since we all agree with our harmful content-sharing project). Could we simply ignore the pleas of people outside our server to cut it out? Could our Digital Safety Plan simply say, “we didn’t get reports”? The Act has penalties for such things, but it would require someone outside our server to report us to the Commission who would then have to investigate. Meanwhile, we’re gleefully sharing harmful content (in this hypothetical example).</p>

<p>So, maybe the Act should require me (and other fedi instances) to document flags I get from outside my server – that is, maybe the Act <em>should</em> see the fediverse as one large network.</p>

<p>But if the Act requires me to document flags coming from outside my server, I could also imagine another problem: being burdened by reporting on malicious or coordinated flagging from outside one’s server. I would have to write up reports for those flags, even if they are done in bad faith. There is language about my being able to ignore “vexatious” or “frivolous” flags, but do I have document them, anyway, to prove that all the reports were, indeed, vexatious?</p>

<p>Taken as a whole, I think the Act should treat each instance as an independent entity.</p>

<h3 id="duty-to-make-certain-content-inaccessible">Duty to Make Certain Content Inaccessible</h3>
<p>Subsection 67 of the Act says that if an operator finds material that exploits children or revictimizes an adult, or finds nonconsensual materials (e.g., revenge “porn”), the operator has to block it and tell the person that it’s blocked. This has to be done in 24 hours.</p>

<p>Obviously, I 100% support this. AoIR.social would act with the swiftness if a member posts such material.</p>

<p>But again, the details are going to matter, and the way the Act understands the fediverse is going to be important. If I block content from another server – not my own – do I have to inform the creator of the content, who did so on the other server? Because that sort of thing often leads to harassment of moderators. I or one of the AoIR.social moderators might get targeted by the sort of person who would maliciously share such content.</p>

<p>The next point, subsection 68, discusses “trivial, frivolous, vexatious” or “bad faith” flags, stating operators can ignore those.</p>

<p>That’s good.</p>

<p>But: “If the operator dismisses the flag, it must, within the period that applies under subsection (5), notify the user who flagged the content of the dismissal.” Again, this is pretty problematic if it’s someone outside my server. The sort of person who submits trivial or vexatious reports is not the sort of person who is going to simply walk away when an admin or mod says to stop.</p>

<h3 id="the-appeals-process">The Appeals Process</h3>

<p>The question of whether I am responsible for reaching out to people on other servers or not is intensified by the “Representations” section (subsection 69), which describes a sort of appeals process:</p>

<blockquote>
  <p>“If the operator of a regulated service makes content inaccessible under subsection 67(1) or 68(3), the operator must, within the period provided for by regulations, give the user who communicated the content on the service and the user who flagged the content, if applicable, an opportunity to make representations as to whether the content is content that sexually victimizes a child or revictimizes a survivor or intimate content communicated without consent.”</p>
</blockquote>

<p>If I’m required to communicate with someone sharing CSAM on another server and ask them to justify their doing so (representing that it is actually OK to share), I will definitely be burdened. I simply want to block them. Or more likely block their server for engaging in poor moderation. I don’t want to negotiate the finer points of CSAM with people who share it.</p>

<p>This is compounded by the “Reconsideration Upon Request” (point 70): “At the request of the user who communicated the content on the service or the user who flagged the content, the operator of a regulated service must reconsider a decision that it made under subsection 69(2).” If I am asked to do this work with someone outside my server, then a full process could be:</p>

<ul>
  <li>consider it and judge it</li>
  <li>communicate with the CSAM provider (“Hey, is this really CSAM?”)</li>
  <li>Hear them out</li>
  <li>Decide</li>
  <li>Reconsider upon request</li>
  <li>Decide</li>
  <li>Reconsider again (“Reconsideration” is mentioned twice)</li>
</ul>

<p>This strikes me as pretty burdensome, as well as a vector for harassment.</p>

<p>And this is not just if the Act sees the fedi as one big network. It could lead to harassment if the Act sees fedi instances as independent, too.</p>

<p>Here’s how: the Act includes the appeals process, because if the Act requires a company like Meta to block stuff without any chance of appeal, that’s problematic, since Meta is going to use automated moderation and will make tons of mistakes.</p>

<p>But for small fediverse instances, I don’t really think a government-mandated appeals process is necessary, nor wanted. Most well-moderated fedi instances are just going to remove accounts of people who post harmful stuff. No appeals. No tolerance. They’re not courts of law. The approach many fedi admins take is: if you want to post X content, you’re free to do so on another server. Does the Act give a bad actor the right to appeal the decision of a fedi admin? I really, really hope not. It would be burdensome and actually cause more harm than good.</p>

<h3 id="duty-to-keep-records">Duty to Keep Records</h3>
<p>Finally, let’s consider subsection 72: “The operator of a regulated service must keep all records, including information and data, that are necessary to determine whether the operator is complying with the operator’s duties under this Act.”</p>

<p>Depending on how the Act is implemented, this could be quite burdensome to operators of small servers. <em>Even if</em> the Act sees fedi instances as independent, I don’t really see the benefits of my keeping records on all my decisions. Do I need to record the date and time every time I block an account or outside instance? Do I need to screenshot every time someone flags something?</p>

<h2 id="conclusion">Conclusion</h2>

<p>In my view, I completely understand the rationale behind the Online Harms Act: I believe corporate social media ought to be regulated. However, I am concerned that, in writing these regulations, the Act’s authors may place some undue burdens on the emerging fediverse, which is comprised of tens of thousands of small servers around the world. If the Act’s authors understand fediverse servers to be independent entities, then the Act <em>might</em> not be so burdensome. If the Act sees the fediverse itself as a large social media network, problems compound. I’m not a lawyer but I believe that the Act is more likely to have the former interpretation.</p>

<p>But even if so, the Act could still burden small, self-funded social media sites by asking already overworked moderators and admins to do more work (or hire/recruit someone specifically to deal with these regulations). If so, the Act’s burdens could happen at a bad time, because the fediverse is starting to emerge as a viable alternative to corporate social media – the very thing the Act is no doubt attempting to address.</p>


       
    <section>
        <h1>Post Tags</h1>
        <ul id="tagList">
            
            <li>
                <a href="/tags/online harms act.html">Online Harms Act</a>
            </li>
            
            <li>
                <a href="/tags/mastodon.html">Mastodon</a>
            </li>
            
            <li>
                <a href="/tags/fediverse.html">Fediverse</a>
            </li>
            
        </ul>
    </section>
    
    <div id="comments">
        <!-- old comment comment <p><em>Comments? I'm still exploring comment system options, but in the meantime, please email me (robertwgehl /at/  protonmail DOTCOM)</em></p> -->
          <!-- load comments from fediverse (mastodon, pleroma,...) "comments" is the name of the variable in front-matter -->
   
   
<!--<div class="article-content">-->
<div class="content">
  <h1>Comments</h1>
  <p>For each of these posts, <a class="link" href="https://aoir.social/@rwg/112249058642915613"> I will also post to Mastodon</a>. If you have a fediverse account and reply to my Mastodon post, that shows up as a comment on this blog <i>unless</i> you change your privacy settings to followers-only or DM. Content warnings will work. You can delete your comment by deleting it through Mastodon.</p>
  <p>Don't have a fediverse account and you want one? Ask me how! robertwgehl AT protonmail . com</p>
  <p><a class="button" href="https://aoir.social/@rwg/112249058642915613">Reply through Fediverse</a></p>
  <p id="mastodon-comments-list"><button id="load-comment">Load comments</button></p>
  <noscript><p>Precisas JavaScript para ver os comentarios.</p></noscript>
  <script src="/assets/js/purify.min.js"></script>
  <script type="text/javascript">
    function escapeHtml(unsafe) {
      return unsafe
           .replace(/&/g, "&amp;")
           .replace(/</g, "&lt;")
           .replace(/>/g, "&gt;")
           .replace(/"/g, "&quot;")
           .replace(/'/g, "&#039;");
   }

    document.getElementById("load-comment").addEventListener("click", function() {
      document.getElementById("load-comment").innerHTML = "Loading";
      fetch('https://aoir.social/api/v1/statuses/112249058642915613/context')
        .then(function(response) {
          return response.json();
        })
        .then(function(data) {
          if(data['descendants'] &&
             Array.isArray(data['descendants']) && 
            data['descendants'].length > 0) {
              document.getElementById('mastodon-comments-list').innerHTML = "";
              data['descendants'].forEach(function(reply) {
                reply.account.display_name = escapeHtml(reply.account.display_name);
                reply.account.emojis.forEach(emoji => {
                  reply.account.display_name = reply.account.display_name.replace(`:${emoji.shortcode}:`,
                    `<img src="${escapeHtml(emoji.static_url)}" alt="Emoji ${emoji.shortcode}" height="20" width="20" />`);
                });
                /* handling CWs, thanks to https://codeberg.org/ashwinvis/m.css/commit/c622ad23dc976c2ce8029e6aee06f57942eb9394 */
                let fediCommentContent
                if (reply.spoiler_text === '') {
                  fediCommentContent = reply.content
                } else {
                  fediCommentContent =
                   `<details><summary><span id="fedicomment-cw">CW: ${escapeHtml(reply.spoiler_text)}</span></summary>
                      ${reply.content}
                   </details>`
                }
                mastodonComment =
                  `<div class="mastodon-comment">
                     <div class="avatar">
                       <img src="${escapeHtml(reply.account.avatar_static)}" class="commentAvatar" alt="">
                     </div>

                     <div class="author">
                        <p>
                          <a href="${reply.account.url}" rel="nofollow">
                            <span>${reply.account.display_name}</span>
                            <span class="disabled">${escapeHtml(reply.account.acct)}</span>
                          </a>
                        </p>
                        <p>
                          <a class="date" href="${reply.uri}" rel="nofollow">
                            ${reply.created_at.substr(0, 10)}
                          </a>
                        </p>
                     </div>
                     
                     <div class="mastodon-comment-content">${fediCommentContent}
                     </div> 
                     
                   </div>`;
                document.getElementById('mastodon-comments-list').appendChild(DOMPurify.sanitize(mastodonComment, {'RETURN_DOM_FRAGMENT': true}));
              });
          } else {
            document.getElementById('mastodon-comments-list').innerHTML = "<p>No comments</p>";
          }
        });
      });
  </script>
</div>




<!--  end of comments section -->


    </div>

    
</div>

    </main>
    <aside>
    <section>
        <h1>Contact</h1>
        <p><strong>Mastodon:</strong> <a rel="me" href="https://aoir.social/@rwg">@rwg@aoir.social</a></p>
        <p><strong>Email: </strong> robertwgehl %AT% protonmail</p>
    </section>

    <section>
        <h1>Archives</h1>
        <ul class="posts">
        
            <li>
                <span class="post-date">Jun 12, 2024</span>
                <a class="post-link" href="/2024/06/12/Maven.html">Maven Ain't So Mavenly</a>
            </li>
        
            <li>
                <span class="post-date">May 24, 2024</span>
                <a class="post-link" href="/2024/05/24/fald.html">Thinking of Switching to the Linux, Fellow Academics?</a>
            </li>
        
            <li>
                <span class="post-date">Apr 30, 2024</span>
                <a class="post-link" href="/2024/04/30/DecentralizedNoncentralized.html">Decentralization or Noncentralization, Bluesky or the Fediverse?</a>
            </li>
        
            <li>
                <span class="post-date">Apr 10, 2024</span>
                <a class="post-link" href="/2024/04/10/Online-Harms-Act.html">Reading the Online Harms Act with my Fediverse Admin Hat On</a>
            </li>
        
            <li>
                <span class="post-date">Mar 14, 2024</span>
                <a class="post-link" href="/2024/03/14/Instances-and-Individuals.html">Researching the Fediverse: Instances and Individuals</a>
            </li>
        
            <li>
                <span class="post-date">Feb 11, 2024</span>
                <a class="post-link" href="/2024/02/11/Move-Slowy-Preview.html">"Move Slowly and Build Bridges" Preview</a>
            </li>
        
            <li>
                <span class="post-date">Dec 16, 2023</span>
                <a class="post-link" href="/2023/12/16/ThoughtsThreads.html">Thoughts on Threads, or Is Mark Zuckerberg Jesus?</a>
            </li>
        
            <li>
                <span class="post-date">Nov 22, 2023</span>
                <a class="post-link" href="/2023/11/22/EthicsAndCOCs.html">Ethics and Codes of Conduct on Mastodon</a>
            </li>
        
            <li>
                <span class="post-date">Nov 10, 2023</span>
                <a class="post-link" href="/2023/11/10/HowUniversitiesLostIT.html">How Universities Lost the Internet</a>
            </li>
        
            <li>
                <span class="post-date">Oct 19, 2023</span>
                <a class="post-link" href="/2023/10/19/AoIR_ASM_preconfernce.html">Alternative Social Media Preconference at AoIR</a>
            </li>
        
            <li>
                <span class="post-date">Oct 15, 2023</span>
                <a class="post-link" href="/2023/10/15/APnonStandard.html">ActivityPub, the Non-Standard Standard</a>
            </li>
        
            <li>
                <span class="post-date">Sep 20, 2023</span>
                <a class="post-link" href="/2023/09/20/blocklists.html">A defense of the humble, importable blocklist</a>
            </li>
        
            <li>
                <span class="post-date">Sep 8, 2023</span>
                <a class="post-link" href="/2023/09/08/ASMupdateBib.html">ASM update, Bibliography Edition</a>
            </li>
        
            <li>
                <span class="post-date">Aug 17, 2023</span>
                <a class="post-link" href="/2023/08/17/OxfordUP.html">Move Slowly and Build Bridges to be published by Oxford University Press</a>
            </li>
        
            <li>
                <span class="post-date">Aug 12, 2023</span>
                <a class="post-link" href="/2023/08/12/ASMupdateFSEP.html">ASM update, August 12 2023</a>
            </li>
        
            <li>
                <span class="post-date">Jul 2, 2023</span>
                <a class="post-link" href="/2023/07/02/GradStudentsPostDocs.html">Seeking Grad Students and Postdocs</a>
            </li>
        
            <li>
                <span class="post-date">Jun 25, 2023</span>
                <a class="post-link" href="/2023/06/25/ASMupdate-Warwick.html">ASM Update, June 25 2023</a>
            </li>
        
            <li>
                <span class="post-date">Jun 16, 2023</span>
                <a class="post-link" href="/2023/06/16/ASMupdate1.html">ASM Update, June 16 2023</a>
            </li>
        
            <li>
                <span class="post-date">May 9, 2023</span>
                <a class="post-link" href="/2023/05/09/ActivityPub2.html">Reading the Minutes of the Social Web Working Group, part 2</a>
            </li>
        
            <li>
                <span class="post-date">Mar 15, 2023</span>
                <a class="post-link" href="/2023/03/15/AOIRsocialCOC.html">AoIR Social's Code of Conduct</a>
            </li>
        
            <li>
                <span class="post-date">Mar 3, 2023</span>
                <a class="post-link" href="/2023/03/03/AOIR-social.html">AOIR.social!</a>
            </li>
        
            <li>
                <span class="post-date">Feb 10, 2023</span>
                <a class="post-link" href="/2023/02/10/bumpAndSlump.html">Bumps, Slumps and the Killer Hype Cycle</a>
            </li>
        
            <li>
                <span class="post-date">Jan 20, 2023</span>
                <a class="post-link" href="/2023/01/20/ActivityPub1.html">Reading the Minutes of the Social Web Working Group, part 1</a>
            </li>
        
            <li>
                <span class="post-date">Jan 3, 2023</span>
                <a class="post-link" href="/2023/01/03/FOSSacademicYIR-copy.html">FOSS Academic Year in Review 2022</a>
            </li>
        
            <li>
                <span class="post-date">Dec 24, 2022</span>
                <a class="post-link" href="/2022/12/24/Playvicous-Christmas.html">A Very Playvicious Christmas</a>
            </li>
        
            <li>
                <span class="post-date">Dec 19, 2022</span>
                <a class="post-link" href="/2022/12/19/Two-new-pubs.html">Two New Publications</a>
            </li>
        
            <li>
                <span class="post-date">Dec 11, 2022</span>
                <a class="post-link" href="/2022/12/11/AOIR-social.html">AOIR.social?</a>
            </li>
        
            <li>
                <span class="post-date">Dec 9, 2022</span>
                <a class="post-link" href="/2022/12/09/FOSSFinds.html">FOSS Finds, Content Moderation webinar</a>
            </li>
        
            <li>
                <span class="post-date">Nov 19, 2022</span>
                <a class="post-link" href="/2022/11/19/Surge.html">Twitter Isn't That Important</a>
            </li>
        
            <li>
                <span class="post-date">Oct 25, 2022</span>
                <a class="post-link" href="/2022/10/25/ASM-not-RWASM.html">Expanding The Conversation (notes on the Pew Alternative Social Media Report)</a>
            </li>
        
            <li>
                <span class="post-date">Oct 18, 2022</span>
                <a class="post-link" href="/2022/10/18/notesOnNobreEtAl.html">More Mastodon Scraping Without Consent (Notes on Nobre et al 2022)</a>
            </li>
        
            <li>
                <span class="post-date">Oct 5, 2022</span>
                <a class="post-link" href="/2022/10/05/deepdivezotero.html">A Deep Dive into a Zotero Workflow</a>
            </li>
        
            <li>
                <span class="post-date">Sep 13, 2022</span>
                <a class="post-link" href="/2022/09/13/FOSSFindsASM.html">FOSS Finds, Scuttlebutt Edition</a>
            </li>
        
            <li>
                <span class="post-date">Aug 17, 2022</span>
                <a class="post-link" href="/2022/08/17/MovingToYork.html">Movin' North</a>
            </li>
        
            <li>
                <span class="post-date">Jun 29, 2022</span>
                <a class="post-link" href="/2022/06/29/FOSSFindsOnDemand.html">FOSS Finds, On Demand Edition</a>
            </li>
        
            <li>
                <span class="post-date">May 26, 2022</span>
                <a class="post-link" href="/2022/05/26/Subscribe.html">(I'm) Mashing That Subscribe Button</a>
            </li>
        
            <li>
                <span class="post-date">Apr 23, 2022</span>
                <a class="post-link" href="/2022/04/23/FOSSFinds.html">FOSS Finds, StoryCorps Edition</a>
            </li>
        
            <li>
                <span class="post-date">Apr 17, 2022</span>
                <a class="post-link" href="/2022/04/17/InterviewWorkflow.html">FOSS Interview Workflow</a>
            </li>
        
            <li>
                <span class="post-date">Mar 26, 2022</span>
                <a class="post-link" href="/2022/03/26/NewBookOldBook.html">New Book, Old Book</a>
            </li>
        
            <li>
                <span class="post-date">Mar 7, 2022</span>
                <a class="post-link" href="/2022/03/07/FOSSFinds.html">FOSS Finds</a>
            </li>
        
            <li>
                <span class="post-date">Feb 15, 2022</span>
                <a class="post-link" href="/2022/02/15/CodingFreedom.html">Coding Freedom, by Biella Coleman</a>
            </li>
        
            <li>
                <span class="post-date">Feb 3, 2022</span>
                <a class="post-link" href="/2022/02/03/Zettlr.html">I Have Settled on Zettlr</a>
            </li>
        
            <li>
                <span class="post-date">Jan 29, 2022</span>
                <a class="post-link" href="/2022/01/29/FOSS-Finds.html">FOSS Finds</a>
            </li>
        
            <li>
                <span class="post-date">Jan 26, 2022</span>
                <a class="post-link" href="/2022/01/26/Very-Kool.html">Very Kool + Jellyfin</a>
            </li>
        
            <li>
                <span class="post-date">Jan 21, 2022</span>
                <a class="post-link" href="/2022/01/21/FossFinds2.html">FOSS Finds, Environment and Labor Edition</a>
            </li>
        
            <li>
                <span class="post-date">Jan 11, 2022</span>
                <a class="post-link" href="/2022/01/11/FOSSFinds.html">FOSS Finds</a>
            </li>
        
            <li>
                <span class="post-date">Jan 6, 2022</span>
                <a class="post-link" href="/2022/01/06/Goal2.html">Goal 2, Initiate</a>
            </li>
        
            <li>
                <span class="post-date">Dec 16, 2021</span>
                <a class="post-link" href="/2021/12/16/CommentsTest.html">Test post for Mastodon Comments</a>
            </li>
        
            <li>
                <span class="post-date">Dec 11, 2021</span>
                <a class="post-link" href="/2021/12/11/Tuxies2021.html">Tuxies 2021</a>
            </li>
        
            <li>
                <span class="post-date">Oct 30, 2021</span>
                <a class="post-link" href="/2021/10/30/PraiseMastodonAgain.html">In Praise of Mastodon, Again</a>
            </li>
        
            <li>
                <span class="post-date">Sep 25, 2021</span>
                <a class="post-link" href="/2021/09/25/Appointments.html">Nextcloud Appointments!</a>
            </li>
        
            <li>
                <span class="post-date">Sep 10, 2021</span>
                <a class="post-link" href="/2021/09/10/Update.html">September update</a>
            </li>
        
            <li>
                <span class="post-date">Jul 18, 2021</span>
                <a class="post-link" href="/2021/07/18/Manjaro-Madness.html">Manjaro Mania!</a>
            </li>
        
            <li>
                <span class="post-date">Jul 3, 2021</span>
                <a class="post-link" href="/2021/07/03/DeGoogleSearch.html">(Almost) De-Googled Research</a>
            </li>
        
            <li>
                <span class="post-date">Jun 24, 2021</span>
                <a class="post-link" href="/2021/06/24/Vacation-and-FDroid.html">A Vacation and F-Droid</a>
            </li>
        
            <li>
                <span class="post-date">May 14, 2021</span>
                <a class="post-link" href="/2021/05/14/FALDupdate.html">FALD Updates</a>
            </li>
        
            <li>
                <span class="post-date">Apr 29, 2021</span>
                <a class="post-link" href="/2021/04/29/Wireguard.html">Messin' with Wireguard</a>
            </li>
        
            <li>
                <span class="post-date">Apr 23, 2021</span>
                <a class="post-link" href="/2021/04/23/DarkMode.html">Sudo Install Dark Mode</a>
            </li>
        
            <li>
                <span class="post-date">Apr 2, 2021</span>
                <a class="post-link" href="/2021/04/02/ZoteroComments.html">Review of Zotero's New PDF Annotation Features</a>
            </li>
        
            <li>
                <span class="post-date">Mar 28, 2021</span>
                <a class="post-link" href="/2021/03/28/RMMess.html">RM Mess</a>
            </li>
        
            <li>
                <span class="post-date">Mar 19, 2021</span>
                <a class="post-link" href="/2021/03/19/cuttingZotero.html">Cutting-Edge Zotero</a>
            </li>
        
            <li>
                <span class="post-date">Mar 11, 2021</span>
                <a class="post-link" href="/2021/03/11/GDPR.html">GDPR Compliance</a>
            </li>
        
            <li>
                <span class="post-date">Mar 10, 2021</span>
                <a class="post-link" href="/2021/03/10/PDFhell.html">PDF Hell</a>
            </li>
        
            <li>
                <span class="post-date">Feb 28, 2021</span>
                <a class="post-link" href="/2021/02/28/LostPosts.html">A Lost Weekend of Lost Posts</a>
            </li>
        
            <li>
                <span class="post-date">Feb 21, 2021</span>
                <a class="post-link" href="/2021/02/21/LinuxMars.html">Linux on Mars</a>
            </li>
        
            <li>
                <span class="post-date">Feb 9, 2021</span>
                <a class="post-link" href="/2021/02/09/MastodonSurvey.html">A Survey for Mastodon Developers, Admins, and Users</a>
            </li>
        
            <li>
                <span class="post-date">Feb 7, 2021</span>
                <a class="post-link" href="/2021/02/07/CloudAcademic.html">I Asked Mastodon About FOSS for Academics. Here's What They Said</a>
            </li>
        
            <li>
                <span class="post-date">Jan 24, 2021</span>
                <a class="post-link" href="/2021/01/24/Staticman.html">Staticman Comments Test Post</a>
            </li>
        
            <li>
                <span class="post-date">Jan 20, 2021</span>
                <a class="post-link" href="/2021/01/20/20-years-wikipedia.html">20 Years of Wikipedia</a>
            </li>
        
            <li>
                <span class="post-date">Jan 8, 2021</span>
                <a class="post-link" href="/2021/01/08/PraiseMastodon.html">In Praise of Mastodon After an Insurrection, or, What if Donald Trump Had Joined Mastodon?</a>
            </li>
        
            <li>
                <span class="post-date">Dec 29, 2020</span>
                <a class="post-link" href="/2020/12/29/Minor-Update.html">Minor Update -- New Publication, No More Hyvor</a>
            </li>
        
            <li>
                <span class="post-date">Dec 27, 2020</span>
                <a class="post-link" href="/2020/12/27/Workflow.html">My Workflow</a>
            </li>
        
            <li>
                <span class="post-date">Dec 20, 2020</span>
                <a class="post-link" href="/2020/12/20/Minor-Update.html">Minor Update -- Tagging System</a>
            </li>
        
            <li>
                <span class="post-date">Dec 15, 2020</span>
                <a class="post-link" href="/2020/12/15/FOSS-Journey.html">My FOSS Journey</a>
            </li>
        
            <li>
                <span class="post-date">Dec 10, 2020</span>
                <a class="post-link" href="/2020/12/10/The-Tuxies-Academic-Style.html">The Tuxies, Academic Style</a>
            </li>
        
            <li>
                <span class="post-date">Dec 6, 2020</span>
                <a class="post-link" href="/2020/12/06/Dreaming-In-Code.html">Dreaming in code</a>
            </li>
        
            <li>
                <span class="post-date">Dec 1, 2020</span>
                <a class="post-link" href="/2020/12/01/Zotero-Tips-and-Tricks.html">Zotero tips and tricks</a>
            </li>
        
            <li>
                <span class="post-date">Nov 27, 2020</span>
                <a class="post-link" href="/2020/11/27/introduction.html">Introduction</a>
            </li>
        
        </ul>
    </section>

</aside>

    <footer>
    <p>All content on this site is licensed <a href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC</a>, unless otherwise noted.</p>

    <!-- Default Statcounter code for FOSS Academic
    https://www.fossacademic.tech/ -->
    <script type="text/javascript">
    var sc_project=12437984; 
    var sc_invisible=1; 
    var sc_security="98ee29d4"; 
    </script>
    <script type="text/javascript"
    src="https://www.statcounter.com/counter/counter.js"
    async></script>
    <noscript><div class="statcounter"><a title="Web Analytics"
    href="https://statcounter.com/" target="_blank"><img
    class="statcounter"
    src="https://c.statcounter.com/12437984/0/98ee29d4/1/"
    alt="Web Analytics"></a></div></noscript>
    <!-- End of Statcounter Code -->

</footer>

    </div>
</body>
</html>
